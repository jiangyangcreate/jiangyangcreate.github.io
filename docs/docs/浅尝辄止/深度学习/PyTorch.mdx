---
sidebar_position: 5
title: PyTorchğŸ”¨
---

å‡¡æ˜¯æ¨¡ä»¿äººçš„ç¥ç»ç½‘ç»œæ„å»ºå‡ºæ¥çš„æ•°å­¦æ¨¡å‹ï¼Œéƒ½å«ç¥ç»ç½‘ç»œï¼Œæˆ–è€…äººå·¥ç¥ç»ç½‘ç»œã€‚

ç¥ç»ç½‘ç»œå¯ä»¥å½’ä¸ºä¸‰å—ï¼š

- BP ç¥ç»ç½‘ç»œï¼ˆBackpropagation Neural Networkï¼‰

ç¥ç»ç½‘ç»œéå¸¸å¤šï¼Œä»Šå¤©ä½ æ ¹æ®ç”Ÿç‰©ç¥ç»ç½‘ç»œæ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œæ˜å¤©æˆ‘æ ¹æ®ç”Ÿç‰©ç¥ç»ç½‘ç»œæ„å»ºä¸€ä¸ªã€‚1986 å¹´ï¼ŒRomelhart å’Œ Mcclellandï¼Œæå‡ºäº†ä¸€ä¸ªç‰¹æ®Šçš„ç»“æ„ï¼Œä½¿ç”¨äº†åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰ç®—æ³•ï¼Œå¹¶å‘½åï¼šBP ç¥ç»ç½‘ç»œã€‚

BP ç¥ç»ç½‘ç»œæå‡ºåï¼Œç¬é—´å´›èµ·åå½“äº†ä¸»åŠ›å†›ã€‚åœ¨ä¸ç‰¹æŒ‡æ—¶ï¼Œå¾€å¾€è¯´ç¥ç»ç½‘ç»œéƒ½æ˜¯æŒ‡ BP ç¥ç»ç½‘ç»œã€‚

- å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼ˆFully Connected Neural Networkï¼‰

å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œæ˜¯ä¸€ç§æœ€åŸºç¡€ã€æœ€ç»å…¸çš„ç¥ç»ç½‘ç»œç»“æ„ã€‚å®ƒçš„ç‰¹ç‚¹æ˜¯ï¼šç½‘ç»œä¸­ç›¸é‚»ä¸¤å±‚çš„æ‰€æœ‰ç¥ç»å…ƒä¹‹é—´éƒ½æœ‰è¿æ¥ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå‰ä¸€å±‚çš„æ¯ä¸ªç¥ç»å…ƒéƒ½ä¸åä¸€å±‚çš„æ¯ä¸ªç¥ç»å…ƒç›¸è¿ã€‚ä¿¡æ¯åªä»è¾“å…¥å±‚æµå‘éšè—å±‚ï¼Œå†æµå‘è¾“å‡ºå±‚ï¼Œæ²¡æœ‰"è·³è¿‡"ä¸­é—´å±‚çš„è¿æ¥ã€‚è¿™ç§ç½‘ç»œæ˜¯æœ€æ—©è¢«å¹¿æ³›ç ”ç©¶å’Œä½¿ç”¨çš„ç¥ç»ç½‘ç»œç±»å‹ï¼Œä¹Ÿæ˜¯ç†è§£æ·±åº¦å­¦ä¹ çš„åŸºç¡€ã€‚

ç”±å¤šä¸ªå…¨è¿æ¥å±‚ç»„æˆçš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œä¹Ÿç§°ä¸ºå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMulti-Layer Perceptron, MLPï¼‰ã€‚

- æ·±åº¦å­¦ä¹ ï¼ˆDeep Learningï¼‰

BP ç¥ç»ç½‘ç»œè™½ç„¶å¾ˆå¥½ç”¨ï¼Œä½†å½“è¦å¤„ç†å›¾è±¡ã€éŸ³é¢‘ã€æ–‡å­—ç­‰é—®é¢˜æ—¶ï¼Œå´ä¸è¡Œäº†ï¼ŒBP ç¥ç»ç½‘ç»œçš„å‚æ•°ä¼šéšç€è¾“å…¥ä¸ªæ•°æŒ‡æ•°å¢é•¿ã€‚ä¾‹å¦‚ä¸€ä¸ª 50 * 50 åƒç´ çš„å›¾è±¡ï¼Œå°±æœ‰ 2500 ä¸ªè¾“å…¥ã€‚å‡è®¾æœ‰ 100 ä¸ªéšèŠ‚ç‚¹ï¼Œåˆ™ 2500 ä¸ªè¾“å…¥åœ¨ç¬¬ä¸€å±‚çš„æƒé‡å‚æ•°å°±æœ‰ 2500 * 100 ä¸ªï¼Œå‚æ•°ä¸ªæ•°é‡çº§å¤ªçˆ†ç‚¸ï¼Œå¯¼è‡´ BP åœ¨æ±‚è§£æ—¶ï¼Œå¾ˆéš¾æ‰¾åˆ°ä¼˜ç§€è§£å°±å®•æœºäº†ã€‚è¿™æœ¬æ¥æ˜¯ä¸ªæ²¡åŠæ³•çš„äº‹ï¼Œä½†ååå›¾è±¡ã€éŸ³é¢‘è¿™äº›é—®é¢˜ï¼Œå®ƒçš„è¾“å…¥å­˜åœ¨å¾ˆä¸¥é‡çš„ç›¸å…³æ€§ï¼ˆä¾‹å¦‚ç›¸é‚»åƒç´ çš„å€¼æ€»æ˜¯ç›¸è¿‘çš„ï¼‰å› æ­¤ï¼Œå¯ä»¥æ ¹æ®è¿™ä¸ªä¸šåŠ¡ç‰¹æ€§ï¼Œè¿›è¡Œè¾“å…¥ä¸ªæ•°å‹ç¼©ï¼Œæˆ–è€…åœ¨æ±‚è§£æ—¶æ ¹æ®è¿™ä¸ªä¸šåŠ¡ç‰¹æ€§è¿›è¡Œç‰¹æ®Šè®¨å·§ï¼ˆä¾‹å¦‚ç›¸é‚»è¾“å…¥å¯¹åº”çš„æƒé‡å‚æ•°å…±äº«ï¼‰ä½¿ BP ç¥ç»ç½‘ç»œåˆå¯ä»¥è§£å†³è¿™ç±»é—®é¢˜äº†ã€‚é—®é¢˜è§£å†³äº†ï¼ŒBP è¿˜æ˜¯ BPï¼ŒæŒ‚ä¸ªåï¼šæ·±åº¦å­¦ä¹ ï¼ä½ å¯ä»¥æŠŠæ·±åº¦å­¦ä¹ çœ‹ä½œæ˜¯ BP ç¥ç»ç½‘ç»œçš„ä¸€ç§åŠ å¼ºç‰ˆï¼Œè§£å†³è¾“å…¥ææææå¤šçš„é—®é¢˜ã€‚

ç¥ç»å…ƒä¸ç¥ç»å…ƒä¹‹é—´æ˜¯ä»¥ç¥ç»å†²åŠ¨çš„æ¨¡å¼è¿›è¡Œä¼ å€¼ï¼Œä¿¡å·åˆ°äº†ç¥ç»å…ƒï¼Œéƒ½æ˜¯ä»¥ç”µä¿¡å·çš„å½¢å¼å­˜åœ¨ï¼Œå½“ç”µä¿¡å·åœ¨ç¥ç»å…ƒç§¯ç´¯åˆ°è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œå°±ä¼šè§¦å‘ç¥ç»å†²åŠ¨ï¼Œå°†ç”µä¿¡å·ä¼ ç»™å…¶å®ƒç¥ç»å…ƒã€‚æ­£æ˜¯æ ¹æ®è¿™ä¸ªæ€è·¯ï¼Œå°±æ„é€ å‡ºäº†ä»¥ä¸Šçš„ç¥ç»ç½‘ç»œç»“æ„ã€‚

:::tip
[åŠ¨ç”»æ¼”ç¤º](https://www.3blue1brown.com/topics/neural-networks)
:::

## ç»å…¸ç¤ºä¾‹

ä¸€å¼  28*28 çš„å›¾ç‰‡å¯ä»¥æŠ½è±¡ä¸ºä¸€ä¸ª 784 ç»´çš„å‘é‡ï¼Œæ¯ä¸ªåƒç´ ç‚¹çš„å€¼å°±æ˜¯å‘é‡çš„ä¸€ä¸ªåˆ†é‡ã€‚æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªå‘é‡ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œï¼Œè¾“å‡ºä¸€ä¸ª 10 ç»´çš„å‘é‡ï¼Œæ¯ä¸ªåˆ†é‡ä»£è¡¨å›¾ç‰‡å±äºæŸä¸ªæ•°å­—çš„æ¦‚ç‡ã€‚

ä¸€ä¸ªæœ‰ 784 ä¸ªè¾“å…¥èŠ‚ç‚¹ï¼Œ16 ä¸ªéšè—èŠ‚ç‚¹ï¼Œ10 ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œç”¨çº¿æ€§ä»£æ•°çš„æ–¹æ³•ç®€æ´è¡¨ç¤ºå±‚ä¸å±‚ä¹‹é—´çš„æƒé‡ï¼š

$$
\begin{aligned}
a_{0}^{1} &= \sigma \left( \sum_{i=1}^{784} (w_{0,i} \cdot a_{i}^{0}) + b_{0} \right)\\
a_{1}^{1} &= \sigma \left( \sum_{i=1}^{784} (w_{1,i} \cdot a_{i}^{0}) + b_{1} \right)\\
&\vdots\\
a_{15}^{1} &= \sigma \left( \sum_{i=1}^{784} (w_{15,i} \cdot a_{i}^{0}) + b_{15} \right)
\end{aligned}
$$

çŸ©é˜µè¡¨ç¤º
$$
\begin{bmatrix}
    w_{0,0} & w_{0,1} & ... & w_{0,784} \\
    w_{1,0} & w_{1,1} & ... & w_{1,784} \\
    ... & ... & ... & ... \\
    w_{15,0} & w_{15,1} & ... & w_{15,784} 
\end{bmatrix}
$$


import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs>
  <TabItem value="torch" label="pytorch" default>
```python showLineNumbers 
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# å®šä¹‰æ•°æ®è½¬æ¢
# Compose æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå°†å¤šä¸ªå˜æ¢ç»„åˆåœ¨ä¸€èµ·
transform = transforms.Compose([
    # å°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡
    transforms.ToTensor(),
    # å°†å›¾åƒçš„åƒç´ å€¼è½¬æ¢ä¸º0.1307é™„è¿‘ï¼Œæ ‡å‡†å·®ä¸º0.3081
    # ä¸ºä»€ä¹ˆæ˜¯0.1307å’Œ0.3081ï¼Ÿ
    # å› ä¸ºMNISTæ•°æ®é›†çš„åƒç´ å€¼æ˜¯0-255ï¼Œè½¬æ¢ä¸º0-1ä¹‹é—´çš„å€¼
    # 0.1307æ˜¯MNISTæ•°æ®é›†çš„å‡å€¼ï¼Œ0.3081æ˜¯MNISTæ•°æ®é›†çš„æ ‡å‡†å·®
    # æ‰€ä»¥éœ€è¦å°†å›¾åƒçš„åƒç´ å€¼è½¬æ¢ä¸º0.1307é™„è¿‘ï¼Œæ ‡å‡†å·®ä¸º0.3081
    transforms.Normalize((0.1307,), (0.3081,))  
])

# åŠ è½½MNISTæ•°æ®é›†
# rootï¼šæ•°æ®é›†çš„æ ¹ç›®å½•
# trainï¼šæ˜¯å¦ä¸ºè®­ç»ƒé›†(è·å–å¸¦æœ‰train=Trueçš„æ•°æ®é›†)
# downloadï¼šæ˜¯å¦ä¸‹è½½æ•°æ®é›†ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™ä¸‹è½½
# transformï¼šæ•°æ®è½¬æ¢
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
# batch_sizeï¼šæ¯ä¸ªbatchï¼ˆæ‰¹æ¬¡ï¼‰çš„å¤§å°
# å¦‚æœbatch_size=1ï¼Œåˆ™æ¯æ¬¡åªå–ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™ä¸éœ€è¦æ‰“ä¹±æ•°æ®é›†
# å¦‚æœbatch_size=1000ï¼Œåˆ™æ¯æ¬¡å–1000ä¸ªæ ·æœ¬ï¼Œåˆ™éœ€è¦æ‰“ä¹±æ•°æ®é›†
# è¾ƒå¤§çš„batch_sizeå¯ä»¥æé«˜è®­ç»ƒé€Ÿåº¦ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´å†…å­˜ä¸è¶³
# shuffleï¼šæ˜¯å¦æ‰“ä¹±æ•°æ®é›†
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# å®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹
# ç»§æ‰¿è‡ªnn.Moduleï¼Œæ‰€ä»¥éœ€è¦å®ç°forwardæ–¹æ³•
class NeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        # è°ƒç”¨çˆ¶ç±»nn.Moduleçš„æ„é€ å‡½æ•°
        super(NeuralNetwork, self).__init__()
        # åˆå§‹åŒ–çº¿æ€§å±‚1
        self.layer1 = nn.Linear(input_size, hidden_size)
        # åˆå§‹åŒ–ReLUæ¿€æ´»å‡½æ•°
        self.relu = nn.ReLU()
        # åˆå§‹åŒ–çº¿æ€§å±‚2
        self.layer2 = nn.Linear(hidden_size, output_size)

    # åœ¨PyTorchä¸­forwardæ˜¯ä¸€ä¸ªç‰¹æ®Šæ–¹æ³•åï¼Œæ˜¯æ¨¡å‹æ­£å‘ä¼ æ’­çš„æ ‡å‡†å‘½å
    # ç”±äºnn.Moduleç»§æ‰¿è‡ªnn.Moduleï¼Œæ‰€ä»¥éœ€è¦å®ç°forwardæ–¹æ³•ï¼Œforwardæ–¹æ³•ä¸­çš„æ•°æ®ä¼šè¢«è®°å½•ï¼Œç”¨äºä¸‹æ–¹loss.backward()è‡ªåŠ¨åå‘ä¼ æ’­
    def forward(self, x):
        # å°†å›¾åƒå±•å¹³
        x = x.reshape(-1, input_size)  
        # æ‰§è¡Œçº¿æ€§å±‚1çš„å‰å‘ä¼ æ’­è®¡ç®—
        x = self.layer1(x)
        # æ‰§è¡ŒReLUæ¿€æ´»å‡½æ•°
        x = self.relu(x)
        # æ‰§è¡Œçº¿æ€§å±‚2çš„å‰å‘ä¼ æ’­è®¡ç®—
        x = self.layer2(x)
        return x

    # # åå‘ä¼ æ’­
    # def backward(self, x):
    #     # æ‰§è¡Œçº¿æ€§å±‚1çš„åå‘ä¼ æ’­è®¡ç®—
    #     x = self.layer1.backward(x)
    #     # æ‰§è¡ŒReLUæ¿€æ´»å‡½æ•°çš„åå‘ä¼ æ’­è®¡ç®—
    #     x = self.relu.backward(x)
    #     # æ‰§è¡Œçº¿æ€§å±‚2çš„åå‘ä¼ æ’­è®¡ç®—
    #     x = self.layer2.backward(x)

# åˆ›å»ºæ¨¡å‹å®ä¾‹
# è¾“å…¥å±‚ï¼š28*28=784
input_size = 28 * 28 
# éšè—å±‚ï¼š128ï¼ˆå¯ä»¥è®¾ç½®ä¸ºå…¶ä»–å€¼ï¼Œé€šå¸¸è®¾ä¸º2çš„å¹‚æ¬¡æ–¹ï¼Œä¸”ä¸è¶…è¿‡è¾“å…¥å±‚çš„ä¸€åŠï¼‰
hidden_size = 128
# è¾“å‡ºå±‚ï¼š10  ï¼ˆå› ä¸ºMNISTæ•°æ®é›†æœ‰10ä¸ªç±»åˆ«ï¼‰
output_size = 10
model = NeuralNetwork(input_size, hidden_size, output_size)

# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
# é‡ç‚¹1ï¼šæŸå¤±å‡½æ•°
# å¸¸è§çš„æŸå¤±å‡½æ•°æœ‰ï¼šäº¤å‰ç†µã€å‡æ–¹è¯¯å·®
# äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼šç”¨äºåˆ†ç±»é—®é¢˜ï¼Œè®¡ç®—é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å·®å¼‚
# å…¬å¼ï¼šloss = -sum(y_true * log(y_pred))
# å‡æ–¹è¯¯å·®ï¼šç”¨äºå›å½’é—®é¢˜ï¼Œè®¡ç®—é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å·®å¼‚
# å…¬å¼ï¼šloss = sum((y_true - y_pred) ** 2)
criterion = nn.CrossEntropyLoss()
# é‡ç‚¹2ï¼šä¼˜åŒ–å™¨
# å¸¸è§çš„ä¼˜åŒ–å™¨æœ‰ï¼šéšæœºæ¢¯åº¦ä¸‹é™ã€Adamã€RMSpropç­‰
# SGDï¼šéšæœºæ¢¯åº¦ä¸‹é™
# å…¬å¼ï¼šoptimizer = optim.SGD(model.parameters(), lr=0.01)
# lrï¼šå­¦ä¹ ç‡ï¼Œç”¨äºæ§åˆ¶æ¯æ¬¡æ›´æ–°å‚æ•°çš„æ­¥é•¿
# momentumï¼šåŠ¨é‡ï¼Œç”¨äºåŠ é€Ÿæ¢¯åº¦ä¸‹é™
# æ¢¯åº¦è®¡ç®—å…¬å¼ä¸momentumæœ‰å…³ï¼Œæœ€ç»ˆæ›´æ–°çš„æ¢¯åº¦ä¸ºï¼šg_v = momentum * g_v + lr * grad
# å…¶ä¸­gradæ˜¯æ¢¯åº¦ï¼Œlræ˜¯å­¦ä¹ ç‡ï¼Œmomentumæ˜¯åŠ¨é‡ï¼Œg_væ˜¯æœ€ç»ˆæ›´æ–°çš„æ¢¯åº¦
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
# è®­ç»ƒæ¨¡å‹ï¼Œepochsæ˜¯è®­ç»ƒçš„è½®æ•°ï¼Œè®­ç»ƒçš„è½®æ•°è¶Šå¤šï¼Œè®­ç»ƒçš„è¶Šå……åˆ†ï¼Œä½†è®­ç»ƒæ—¶é—´è¶Šé•¿
# è®­ç»ƒçš„å‰æœŸæ¢¯åº¦ä¸‹é™è¾ƒå¤šï¼ŒåæœŸæ¢¯åº¦ä¸‹é™è¾ƒå°‘ï¼Œå› ä¸ºåæœŸæ¢¯åº¦è¾ƒå°ï¼Œæ‰€ä»¥éœ€è¦è¾ƒå°çš„å­¦ä¹ ç‡
epochs = 5

for epoch in range(epochs):
    running_loss = 0.0
    for i, (images, labels) in enumerate(train_loader):
        # æ¨¡å‹è®­ç»ƒ,æŠŠæ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        # æ¿€æ´»BatchNormå±‚çš„å‚æ•°æ›´æ–°æœºåˆ¶ï¼Œä½¿ç”¨å½“å‰æ‰¹æ¬¡çš„å‡å€¼å’Œæ–¹å·®è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¹¶æ›´æ–°è¿è¡Œæ—¶ç»Ÿè®¡å€¼
        # æ¿€æ´»Dropoutå±‚ï¼Œéšæœºä¸¢å¼ƒä¸€éƒ¨åˆ†ç¥ç»å…ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        # ç¡®ä¿æ¢¯åº¦è®¡ç®—å’Œå‚æ•°æ›´æ–°æ­£å¸¸è¿›è¡Œ
        model.train()
        # å‰å‘ä¼ æ’­
        outputs = model(images)
        # è®¡ç®—æŸå¤±
        loss = criterion(outputs, labels)
        # æ¢¯åº¦æ¸…é›¶ï¼Œå¦‚æœä¸æ¸…é›¶ï¼Œæ¢¯åº¦ä¼šç´¯åŠ 
        optimizer.zero_grad()
        # åå‘ä¼ æ’­
        '''
PyTorchçš„è‡ªåŠ¨å¾®åˆ†å¼•æ“å¾ˆæ™ºèƒ½ï¼ˆä½ ä¹Ÿå¯ä»¥åœ¨æ¨¡å‹ä¸­åƒæ„å»ºå‰å‘ä¼ æ’­ä¸€æ ·ï¼Œæ‰‹åŠ¨è®¾ç½®backwardæ–¹æ³•ï¼‰ï¼Œå®ƒèƒ½å¤Ÿè‡ªåŠ¨å¤„ç†æ¢¯åº¦åœ¨è®¡ç®—å›¾ä¸­çš„æµåŠ¨ã€‚
ä¸éœ€è¦æˆ‘ä»¬æ˜ç¡®æŒ‡å®šæ¢¯åº¦åº”è¯¥ä¼ æ’­åˆ°å“ªä¸ªæ¨¡å‹ã€‚
åªè¦æ¨¡å‹çš„å‚æ•°å‚ä¸äº†æŸå¤±çš„è®¡ç®—ï¼Œå®ƒä»¬å°±ä¼šè‡ªåŠ¨æˆä¸ºæ¢¯åº¦è®¡ç®—çš„ä¸€éƒ¨åˆ†ã€‚
1. å½“ä½ æ‰§è¡Œå‰å‘è®¡ç®—æ—¶ï¼ŒPyTorchä¼šåœ¨åå°æ„å»ºä¸€ä¸ªåŠ¨æ€è®¡ç®—å›¾ï¼Œè®°å½•æ‰€æœ‰æ“ä½œåŠå…¶ä¾èµ–å…³ç³»ã€‚æ¯ä¸ªå¼ é‡éƒ½ä¼šå­˜å‚¨ä¿¡æ¯ï¼ŒæŒ‡å‘åˆ›å»ºå®ƒçš„æ“ä½œï¼ˆå­˜å‚¨åœ¨`grad_fn`å±æ€§ä¸­ï¼‰ã€‚
2. æŸå¤±å‡½æ•°ï¼ˆå¦‚`loss`ï¼‰æ˜¯è¿™ä¸ªè®¡ç®—å›¾çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œé€šè¿‡`.backward()`æ–¹æ³•ï¼ŒPyTorchä¼šä»è¿™ä¸ªèŠ‚ç‚¹å¼€å§‹æ²¿ç€è®¡ç®—å›¾å‘åè¿½è¸ªæ‰€æœ‰éœ€è¦è®¡ç®—æ¢¯åº¦çš„å‚æ•°ã€‚
3. å½“åˆ›å»ºæ¨¡å‹æ—¶ï¼Œæ‰€æœ‰å‚æ•°éƒ½ä¼šè‡ªåŠ¨è®¾ç½®`requires_grad=True`ï¼Œè¿™äº›å‚æ•°ä¼šè¢«çº³å…¥è®¡ç®—å›¾ä¸­ã€‚å½“è®¡ç®—æŸå¤±æ—¶ï¼Œè¿™äº›å‚æ•°é€šè¿‡ä¸€ç³»åˆ—æ“ä½œä¸æŸå¤±å‡½æ•°ç›¸è¿æ¥ã€‚
4. PyTorchä¼šè‡ªåŠ¨è¿½è¸ªä»æŸå¤±åˆ°å„ä¸ªå‚æ•°çš„è·¯å¾„ï¼Œä¸éœ€è¦æ˜ç¡®æŒ‡å®šæ¨¡å‹ã€‚è¿™æ˜¯å› ä¸ºè®¡ç®—å›¾åŒ…å«äº†æ‰€æœ‰æ“ä½œçš„å®Œæ•´è®°å½•ï¼ŒåŒ…æ‹¬å“ªäº›å‚æ•°å‚ä¸äº†è®¡ç®—ã€‚
        '''
        loss.backward()
        # æ›´æ–°å‚æ•°,æ›´æ–°å‚æ•°çš„å…¬å¼ä¸ºï¼šweight = weight - lr * grad
        optimizer.step()
        # ç´¯è®¡æŸå¤±
        running_loss += loss.item()
        
    # æ¯ä¸ªepochç»“æŸåè®¡ç®—å‡†ç¡®ç‡
    correct = 0
    total = 0
    # æµ‹è¯•æ¨¡å‹
    # æµ‹è¯•æ¨¡å‹æ—¶ï¼Œä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œå³å…³é—­åå°è‡ªåŠ¨çš„æ¢¯åº¦è®¡ç®—
    with torch.no_grad():
        # åŠ è½½æµ‹è¯•é›†
        for images, labels in test_loader:
            # æµ‹è¯•æ¨¡å‹ï¼ŒæŠŠæ¨¡å‹è®¾ç½®ä¸ºæµ‹è¯•æ¨¡å¼
            # BatchNormå±‚ä¼šä½¿ç”¨è¿è¡Œæ—¶ç»Ÿè®¡æ•°æ®è€Œä¸æ˜¯æ‰¹æ¬¡ç»Ÿè®¡æ•°æ®
            # Dropoutå±‚ä¼šåœæ­¢éšæœºä¸¢å¼ƒç¥ç»å…ƒ
            model.eval()
            outputs = model(images)
            # è·å–é¢„æµ‹å€¼
            # åŒºåˆ«ä¸torch.maximum
            # torch.maxä¼šè¿”å›ä¸¤ä¸ªå€¼ï¼Œä¸€ä¸ªæ˜¯æœ€å¤§å€¼ï¼Œä¸€ä¸ªæ˜¯æœ€å¤§å€¼çš„ç´¢å¼•
            # è€Œtorch.maximumåªä¼šè¿”å›æœ€å¤§å€¼
            # ç‚¹å‡»è¿›å…¥è¿™ä¸ªæ–¹æ³•ï¼Œå¯ä»¥çœ‹åˆ°ç¤ºä¾‹
            _, predicted = torch.max(outputs.data, 1)
            # ç´¯è®¡æ ·æœ¬æ•°,labels.size(0) è¡¨ç¤ºå½“å‰æ‰¹æ¬¡ä¸­æ ·æœ¬çš„æ•°é‡ã€‚
            # åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œå½“ä½¿ç”¨ DataLoader åŠ è½½æ•°æ®æ—¶ï¼Œæ¯ä¸ªæ‰¹æ¬¡å¯èƒ½åŒ…å«å¤šä¸ªæ ·æœ¬ï¼ˆç”± batch_size å†³å®šï¼‰ã€‚
            total += labels.size(0)
            # ç´¯è®¡æ­£ç¡®æ ·æœ¬æ•°
            # è®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®å€¼ç›¸ç­‰çš„æ ·æœ¬æ•°
            print(predicted) # å¾—åˆ°é•¿åº¦ä¸ºbatch_sizeçš„å‘é‡ï¼ˆé¢„æµ‹å€¼ï¼‰
            print(labels) # å¾—åˆ°é•¿åº¦ä¸ºbatch_sizeçš„å‘é‡(çœŸå®å€¼)
            
            # è®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®å€¼ç›¸ç­‰çš„æ ·æœ¬æ•°
            test = (predicted == labels)
            # [ True .... False ],Pythonè®¡ç®—å¸ƒå°”å€¼çš„æ—¶å€™ï¼ŒæŠŠTrueå½“ä½œ1ï¼ŒFalseå½“ä½œ0
            # æ‰€ä»¥test.sum()å°±æ˜¯é¢„æµ‹å€¼ä¸çœŸå®å€¼ç›¸ç­‰çš„æ ·æœ¬æ•°
            # .item() æ–¹æ³•ç”¨äºå°†å¼ é‡è½¬æ¢ä¸ºæ ‡é‡ï¼ˆå³ä¸€ä¸ªæ•°å€¼ï¼‰ç”¨äºåŠ æ³•è®¡ç®—
            correct += test.sum().item()
    
    accuracy = correct / total
    print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}')

# è¯„ä¼°æ¨¡å‹
correct = 0
total = 0
# å…³é—­æ¢¯åº¦è®¡ç®—
with torch.no_grad():
    for images, labels in test_loader:
        # æµ‹è¯•æ¨¡å‹ï¼ŒæŠŠæ¨¡å‹è®¾ç½®ä¸ºæµ‹è¯•æ¨¡å¼
        """
æœ¬ä»£ç ä¸åŠ model.train()å’Œmodel.eval()åŸå› æœ‰ä»¥ä¸‹å‡ ç‚¹ï¼š
1. æ¨¡å‹ä¸­æ²¡æœ‰BatchNormå’ŒDropoutç­‰å±‚ï¼Œè°ƒç”¨ä¸å¦ç¡®å®ä¸ä¼šæœ‰åŒºåˆ«
2. åˆ›å»ºæ¨¡å‹åï¼ŒPyTorché»˜è®¤æ˜¯è®­ç»ƒæ¨¡å¼ï¼Œæ‰€ä»¥ä¸è°ƒç”¨model.train()ä¹Ÿèƒ½æ­£å¸¸è®­ç»ƒï¼Œåªæœ‰æ˜ç¡®è°ƒç”¨model.eval()åæ‰ä¼šåˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼

æ›´å¤æ‚çš„æ¨¡å‹å¦‚ResNetã€BERTç­‰éƒ½åŒ…å«è¿™äº›å±‚ã€‚
æ‰€ä»¥éœ€è¦å…»æˆä¹ æƒ¯å§‹ç»ˆåœ¨ç›¸åº”é˜¶æ®µè°ƒç”¨model.train()å’Œmodel.eval()
è¿™æ ·ä»£ç æ›´è§„èŒƒï¼Œä¹Ÿèƒ½é¿å…åœ¨æ¨¡å‹å˜å¤æ‚åå‡ºç°æ„å¤–é—®é¢˜ã€‚
        """
        model.eval()
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = correct / total
print(f'æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}')
```
  </TabItem>

<TabItem value="numpy" label="numpy">
```python showLineNumbers 
import numpy

# ç¡®ä¿ç»˜å›¾åœ¨æ­¤nbä¸­è¿›è¡Œï¼Œè€Œä¸æ˜¯åœ¨å¤–éƒ¨çª—å£ä¸­
class NeuralNetwork:
    # åˆå§‹åŒ–ç¥ç»ç½‘ç»œ
    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):
        # è®¾ç½®æ¯ä¸ªè¾“å…¥ã€éšè—å’Œè¾“å‡ºå±‚çš„èŠ‚ç‚¹æ•°
        self.inodes = inputnodes
        self.hnodes = hiddennodes
        self.onodes = outputnodes
        # è¿æ¥æƒé‡çŸ©é˜µï¼Œwih å’Œ who
        # æ•°ç»„ä¸­çš„æƒé‡æ˜¯ w_i_jï¼Œå…¶ä¸­é“¾æ¥ä»ä¸Šä¸€å±‚çš„èŠ‚ç‚¹ i åˆ°ä¸‹ä¸€å±‚çš„èŠ‚ç‚¹ j
        # w11 w21
        # w12 w22 ç­‰ç­‰
        # è¿”å›æ­£æ€åˆ†å¸ƒæ•°æ®
        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))
        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))
        # å­¦ä¹ ç‡
        self.lr = learningrate
        # æ¿€æ´»å‡½æ•°æ˜¯ sigmoid å‡½æ•°
        self.activation_function = lambda x: 1 / (1 + numpy.exp(-x))
        pass
    
    # è®­ç»ƒç¥ç»ç½‘ç»œ
    def train(self, è¾“å…¥åˆ—è¡¨, ç›®æ ‡åˆ—è¡¨):
        # å°†è¾“å…¥åˆ—è¡¨è½¬æ¢ä¸º 2D æ•°ç»„
        inputs = numpy.array(è¾“å…¥åˆ—è¡¨, ndmin=2).T
        targets = numpy.array(ç›®æ ‡åˆ—è¡¨, ndmin=2).T
        # è®¡ç®—è¿›å…¥éšè—å±‚çš„ä¿¡å·
        hidden_inputs = numpy.dot(self.wih, inputs)
        # è®¡ç®—ä»éšè—å±‚å‡ºæ¥çš„ä¿¡å·
        hidden_outputs = self.activation_function(hidden_inputs)
        
        # è®¡ç®—è¿›å…¥æœ€ç»ˆè¾“å‡ºå±‚çš„ä¿¡å·
        final_inputs = numpy.dot(self.who, hidden_outputs)
        # è®¡ç®—ä»æœ€ç»ˆè¾“å‡ºå±‚å‡ºæ¥çš„ä¿¡å·
        final_outputs = self.activation_function(final_inputs)
        
        # è¾“å‡ºå±‚è¯¯å·®æ˜¯ (ç›®æ ‡ - å®é™…)
        output_errors = targets - final_outputs
        # éšè—å±‚è¯¯å·®æ˜¯è¾“å‡ºè¯¯å·®ï¼ŒæŒ‰æƒé‡æ‹†åˆ†ï¼Œé‡æ–°ç»„åˆåœ¨éšè—èŠ‚ç‚¹å¤„
        hidden_errors = numpy.dot(self.who.T, output_errors)
        
        # æ›´æ–°éšè—å±‚å’Œè¾“å‡ºå±‚ä¹‹é—´çš„é“¾æ¥æƒé‡
        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))
        
        # æ›´æ–°è¾“å…¥å±‚å’Œéšè—å±‚ä¹‹é—´çš„é“¾æ¥æƒé‡
        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))
        
        pass
    
    # æŸ¥è¯¢ç¥ç»ç½‘ç»œ
    def query(self, è¾“å…¥åˆ—è¡¨):
        # å°†è¾“å…¥åˆ—è¡¨è½¬æ¢ä¸º 2D æ•°ç»„
        inputs = numpy.array(è¾“å…¥åˆ—è¡¨, ndmin=2).T
        
        # è®¡ç®—è¿›å…¥éšè—å±‚çš„ä¿¡å·
        hidden_inputs = numpy.dot(self.wih, inputs)
        # è®¡ç®—ä»éšè—å±‚å‡ºæ¥çš„ä¿¡å·
        hidden_outputs = self.activation_function(hidden_inputs)
        
        # è®¡ç®—è¿›å…¥æœ€ç»ˆè¾“å‡ºå±‚çš„ä¿¡å·
        final_inputs = numpy.dot(self.who, hidden_outputs)
        # è®¡ç®—ä»æœ€ç»ˆè¾“å‡ºå±‚å‡ºæ¥çš„ä¿¡å·
        final_outputs = self.activation_function(final_inputs)
        
        return final_outputs
    

input_nodes = 64
hidden_nodes = 32
output_nodes = 10

# å­¦ä¹ ç‡
learning_rate = 0.2

# åˆ›å»ºç¥ç»ç½‘ç»œå®ä¾‹
n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)

from sklearn import datasets
from sklearn.model_selection import train_test_split
# åŠ è½½æ•°æ®é›†
digits = datasets.load_digits()
X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.1,random_state=0)

epochs = 2  # å›å£°å¢åŠ æ ·æœ¬é‡
 
for i in range(epochs):
    for record in zip(y_train, X_train):
        y, X = record
        # ç¼©æ”¾å’Œç§»åŠ¨è¾“å…¥
        inputs = (numpy.asfarray(X) / 16.0 * 0.99) + 0.01
        # åˆ›å»ºç›®æ ‡è¾“å‡ºå€¼ï¼ˆå…¨éƒ¨ä¸º 0.01ï¼Œé™¤äº†æ‰€éœ€æ ‡ç­¾ä¸º 0.99ï¼‰
        targets = numpy.zeros(output_nodes) + 0.01
        # all_values[0] æ˜¯æ­¤è®°å½•çš„ç›®æ ‡æ ‡ç­¾
        targets[int(y)] = 0.99
        n.train(inputs, targets)
# æˆ‘ä»¬è‡ªå·±çš„å›¾åƒæµ‹è¯•æ•°æ®é›†
our_own_dataset = []

for i in zip(y_test, X_test):
    label, img_array = i
    # img_data  = 16.0 - img_array
    # ç„¶åå°†æ•°æ®ç¼©æ”¾åˆ°èŒƒå›´ä» 0.01 åˆ° 1.0
    img_data = (img_array / 16.0 * 0.99) + 0.01
    # å°†æ ‡ç­¾å’Œå›¾åƒæ•°æ®é™„åŠ åˆ°æµ‹è¯•æ•°æ®é›†
    record = numpy.append(label, img_data)
    our_own_dataset.append(record)
    pass

right = 0
error = 0
for item in range(len(our_own_dataset)):
    # æ­£ç¡®ç­”æ¡ˆæ˜¯ç¬¬ä¸€ä¸ªå€¼
    correct_label = our_own_dataset[item][0]
    # print(correct_label)

    # æ•°æ®æ˜¯å‰©ä½™çš„å€¼
    inputs = our_own_dataset[item][1:]
 
    # æŸ¥è¯¢ç½‘ç»œ
    outputs = n.query(inputs)

    # æœ€é«˜å€¼çš„ç´¢å¼•å¯¹åº”äºæ ‡ç­¾
    label = numpy.argmax(outputs)
    if label != correct_label:
        error += 1
    else:
        right += 1
print(right / (right + error))

```
 </TabItem>
</Tabs>

## éªŒè¯ç è¯†åˆ«

åœ¨ç°å®ç”Ÿæ´»ä¸­å¹¶ä¸å­˜åœ¨ä¸€ä¸ªåœºæ™¯ï¼Œç»™ä½ å•ç‹¬ä¸€ä¸ªæ•°å­—è®©ä½ è¿›è¡Œè¯†åˆ«ã€‚ä½†æ˜¯æœ‰ä¸€äº›ç±»ä¼¼çš„åœºæ™¯ï¼Œè­¬å¦‚ï¼šè½¦ç‰Œå·ã€å‘ç¥¨å·ç ã€ç½‘ç«™çš„éªŒè¯ç ç­‰ã€‚é’ˆå¯¹è¿™äº›åœºæ™¯ï¼Œæˆ‘æä¾›ä¸€äº›æ€è·¯ï¼š

- æˆ‘ä»¬éœ€è¦å¯¹å›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªåˆ†å‰² 4 ä¸ªå­—çš„éªŒè¯ç çš„ä¾‹å­
- åˆ†å‰²å®Œæˆåå†å°†ç»“æœä¾æ¬¡åšæ ‡å‡†åŒ–å¤„ç†ï¼Œè­¬å¦‚å‹ç¼©æ•°ç»„å¤§å°
- é€ä¸€è¯†åˆ«ï¼Œè¿”å›ç»“æœ

ä¸‹é¢ä»£ç ä»¥`numpy`ç‰ˆæœ¬çš„ç¥ç»ç½‘ç»œä¸ºä¾‹ï¼š

```python showLineNumbers 
from PIL import ImageFont,Image,ImageDraw
# ç”Ÿæˆä¸€ä¸ªéªŒè¯ç 
c_chars = "0 1 2 3 4"
path = 'test.png'
size = (100,24)                             #å›¾ç‰‡å¤§å°
img = Image.new("RGB",size)
draw = ImageDraw.Draw(img)                  #drawä¸€ä¸ª
font = ImageFont.truetype("arial.ttf", 23)      #å­—ä½“
draw.text((5,0),c_chars,font=font,fill="white") #å­—é¢œè‰²
# img.show()
img.save(path)

# åˆ†å‰²å›¾ç‰‡
def sliceImg(img_path, count = 5):
    img = Image.open(img_path).convert("L")
    w, h = img.size
    eachWidth = int(w/count)
    for i in range(count):
        box = (i * eachWidth, 0, (i + 1) * eachWidth, h)
        yield img.crop(box)

# è½¬åŒ–å›¾ç‰‡
def exchange(img):
    target_size = (8, 8)
    resized_image = img.resize(target_size)
    # resized_image.show()
    return resized_image


out = ""
for i in sliceImg(path):
    # .flatten()æ–¹æ³•å°†æ•°ç»„è½¬åŒ–ä¸ºåˆ—è¡¨
    original_array =  numpy.array(exchange(i)).flatten()
    # å°†æ•°æ®0-1åŒ–
    inputs = (original_array / 255.0 * 0.99) + 0.01
    # æŸ¥è¯¢ç½‘ç»œ
    outputs = n.query(inputs)
    # print(outputs)
    # æœ€é«˜å€¼çš„ç´¢å¼•å¯¹åº”äºæ ‡ç­¾
    label = numpy.argmax(outputs)
    out+=str(label)
print(out)
```

### è°ƒä¼˜

ä»ç»“æœä¸Šæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œ0ã€1ã€2ã€4 è¢«æ­£ç¡®çš„è¯†åˆ«äº†ã€‚ä½†æ•°å­— 3 æ²¡æœ‰è¢«æ­£ç¡®çš„è¯†åˆ«ã€‚è¯·æ€è€ƒè¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œæœ€æœ‰æ•ˆçš„ä¼˜åŒ–æ–¹å¼ã€‚

ç­”æ¡ˆAï¼šä¼˜åŒ–å›¾ç‰‡è£åˆ‡ç»“æ„ï¼Œä½¿ç”¨å…¶ä»–è†¨èƒ€ã€ä¾µèš€ã€over paddingç­‰ç®—æ³•

ç­”æ¡ˆBï¼šå¢åŠ å›å£°ï¼Œå¼ºåŒ–æ¨¡å‹èƒ½åŠ›

ç­”æ¡ˆCï¼šå¢åŠ è®­ç»ƒæ¬¡æ•°

ç­”æ¡ˆDï¼šå…¶ä»–

<details>


```python showLineNumbers 
# è¿™é‡Œæˆ‘æ£€æŸ¥äº†è½¬åŒ–å8*8çš„æ•°å­—3çš„å›¾ç‰‡ï¼Œå¯¹æ¯”äº†æ‰‹å†™æ•°å­—3å’Œæ‰‹å†™æ•°å­—8ï¼Œ
# æˆ‘è®¤ä¸ºç”Ÿæˆçš„æ•°å­—3ä¸æ‰‹å†™8æ›´æ¥è¿‘ç›¸å¯¹äºä¸æ‰‹å†™3
# æ‰€ä»¥æˆ‘è®¤ä¸ºçš„è§£å†³çš„æ–¹æ¡ˆæ˜¯ï¼šç»™æ¨¡å‹å†å–‚ä¸€äº›ç”Ÿæˆæ•°å­—3çš„æ ·æœ¬ã€‚

from PIL import ImageFont,Image,ImageDraw
# ç”Ÿæˆä¸€ä¸ªéªŒè¯ç 
c_chars = "3 3 3 3 3"
path = 'test.png'
size = (100,24)                             #å›¾ç‰‡å¤§å°
img = Image.new("RGB",size)
draw = ImageDraw.Draw(img)                  #drawä¸€ä¸ª
font = ImageFont.truetype("arial.ttf", 23)      #å­—ä½“
draw.text((5,0),c_chars,font=font,fill="white") #å­—é¢œè‰²
# img.show()
img.save(path)

# åˆ†å‰²å›¾ç‰‡
def sliceImg(img_path, count = 5):
    img = Image.open(img_path).convert("L")
    w, h = img.size
    eachWidth = int(w/count)
    for i in range(count):
        box = (i * eachWidth, 0, (i + 1) * eachWidth, h)
        yield img.crop(box)

# è½¬åŒ–å›¾ç‰‡
def exchange(img):
    target_size = (8, 8)
    resized_image = img.resize(target_size)
    # resized_image.show()
    return resized_image


for i in sliceImg(path):
    # .flatten()æ–¹æ³•å°†æ•°ç»„è½¬åŒ–ä¸ºåˆ—è¡¨
    original_array =  numpy.array(exchange(i)).flatten()
    # å°†æ•°æ®0-1åŒ–
    inputs = (original_array / 255.0 * 0.99) + 0.01
    targets = numpy.zeros(output_nodes) + 0.01
    # all_values[0] æ˜¯æ­¤è®°å½•çš„ç›®æ ‡æ ‡ç­¾
    targets[int(3)] = 0.99
    n.train(inputs, targets)

# ç”Ÿæˆä¸€ä¸ªéªŒè¯ç 
c_chars = "0 1 2 3 4"
path = 'test.png'
size = (100,24)                             #å›¾ç‰‡å¤§å°
img = Image.new("RGB",size)
draw = ImageDraw.Draw(img)                  #drawä¸€ä¸ª
font = ImageFont.truetype("arial.ttf", 23)      #å­—ä½“
draw.text((5,0),c_chars,font=font,fill="white") #å­—é¢œè‰²
# img.show()
img.save(path)

out = ""
for i in sliceImg(path):
    # .flatten()æ–¹æ³•å°†æ•°ç»„è½¬åŒ–ä¸ºåˆ—è¡¨
    original_array =  numpy.array(exchange(i)).flatten()
    # å°†æ•°æ®0-1åŒ–
    inputs = (original_array / 255.0 * 0.99) + 0.01
    # æŸ¥è¯¢ç½‘ç»œ
    outputs = n.query(inputs)
    # print(outputs)
    # æœ€é«˜å€¼çš„ç´¢å¼•å¯¹åº”äºæ ‡ç­¾
    label = numpy.argmax(outputs)
    out+=str(label)
print(out)

# ç§»é™¤ç”Ÿæˆçš„å›¾ç‰‡ï¼Œä¿æŒæ–‡ä»¶å¤¹çš„æ•´æ´
import os
os.remove(path)
```

å¯ä»¥çœ‹åˆ°è¾“å‡ºçš„ç»“æœå·²ç»æ­£ç¡®çš„æ˜¾ç¤ºä¸º1ã€2ã€3ã€4ã€‚å¦‚æ­¤ä¸€æ¥ã€‚æ¨¡å‹å°±ç®—è®­ç»ƒå®Œæˆäº†ã€‚

</details>
