---
sidebar_position: 5
title: 分布式训练
---

## 原理部分

DDP 与 NvLink 是目前大模型分布式训练最主要的技术支撑。

ddp 是 pytorch 推出的一个用于分布式训练的工具，它可以帮助我们方便地进行分布式训练。

deepspeed 是微软推出的一个用于分布式训练的工具，它可以帮助我们方便地进行分布式训练。

accelerate 是 Hugging Face 推出的一个用于分布式训练的工具， Accelerate。这不是 PyTorch 之上的高级框架，只是一个薄包装器。


分布式训练常见的2种模式：
- 单机多卡
- 多机多卡
