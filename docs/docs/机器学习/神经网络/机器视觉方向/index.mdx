---
sidebar_position: 2
title: 机器视觉方向
---

早在深度学习之前，人们就开始探索图像的处理了，OpenCV 诞生于深度学习之前，是功能最全面的开源库。它提供了从最基础的图像读写、处理到复杂的特征匹配、目标跟踪、校准等一系列工具。其核心优势在于传统的计算机视觉算法，如图像处理、滤波、形态学操作等。

它向前承接传统以数组为单位的图像处理，向后承接深度学习，还提供很多预处理工具，是传统图像处理与深度学习之间重要的桥梁。

## 安装

opencv（opensource computer vision）开源计算机视觉库，包含大量的图像处理函数。

[opencv-python](https://github.com/opencv/opencv-python)需要根据环境选择正确的包

有4个不同的包，你<Highlight>只能选择其中的一个。不要在同一环境中安装多个不同的包。</Highlight>

所有包都使用相同的名称空间（`cv2`）。如果你在同一环境中安装了多个不同的包，请使用 ``pip uninstall`` 卸载所有包，然后只重新安装一个包。

**a.** 针对标准桌面环境的包（适用于 Windows、macOS、几乎所有 GNU/Linux 发行版）

- 选项 1 - 主模块包：``pip install opencv-python``
- 选项 2 - 完整包（包含主模块和 contrib/extra 模块）：``pip install opencv-contrib-python``（请参考 [OpenCV 文档](https://docs.opencv.org/master/) 中的 contrib/extra 模块列表）

**b.** 针对服务器（无窗口）环境的包（例如 Docker、云环境等），无 GUI 库依赖

这些包比前面两种包更小，因为它们不包含任何图形用户界面功能（未编译 Qt 或其他 GUI 组件）。这意味着这些包避免了对 X11 库的庞大依赖，从而例如可以生成更小的 Docker 镜像。如果你不使用 `cv2.imshow` 等函数，或者你使用其他包（例如 PyQt）来构建界面而非 OpenCV，则应始终使用这些包。

- 选项 3 - 无窗口主模块包：``pip install opencv-python-headless``
- 选项 4 - 无窗口完整包（包含主模块和 contrib/extra 模块）：``pip install opencv-contrib-python-headless``（请参考 [OpenCV 文档](https://docs.opencv.org/master/) 中的 contrib/extra 模块列表）


OpenCv作为开源软件，自然有大量的教程，我读过一些纸质书籍，也看过一些开源教程，总体来说，对于入门与进阶来说，需要的是细致的基础讲解、完整的处理流程，非常推荐官方的[OpenCV-Python教程](https://opencv-python-tutorials.readthedocs.io/)。


## 图像读取与显示

### 图像读取

函数签名：`cv2.imread(filename, flags=cv2.IMREAD_COLOR) -> image`

参数说明：

- `filename`：要读取的文件名
- `flags`：读取标志，默认值为cv2.IMREAD_COLOR，表示读取为BGR格式。可选参数：
    - cv2.IMREAD_COLOR：读取为BGR格式，默认值。对应数值为1。
    - cv2.IMREAD_GRAYSCALE：读取为灰度图，对应数值为0。
    - cv2.IMREAD_UNCHANGED：读取为原图，包含alpha通道，对应数值为-1。

返回值：

- 返回读取的图像对象, <Highlight>如果读取失败, 不报错，返回None</Highlight>
- <Highlight>CV2默认使用系统编码，如果文件路径含中文无法正常读取，需要把系统编码改为`utf-8`。</Highlight>

图像对象的常用属性：
- `shape`：图像的形状，(height, width, channels) 其中channels为3、4，表示通道数为RGB、RGBA（A是透明度），如果是灰度、二值图，通道数为1的情况会只返回(height, width)。
- `size`：图像的像素数，height * width * channels
- `dtype`：图像的数据类型
- `ndim`：图像的维度
- `itemsize`：图像的元素大小
- `nbytes`：图像的内存大小

```python showLineNumbers
import cv2
path= "10.jpg"
img = cv2.imread(path)
print(img.shape) 
```

### 图像保存

函数签名：`cv2.imwrite(filename, img, [params])`

参数说明：

- `filename`：要保存的文件名
- `img`：要保存的图像对象(数据)
- `params`：可选参数，<Highlight>用于指定保存的格式和质量</Highlight>，可选参数：
    - cv2.IMWRITE_JPEG_QUALITY：JPEG图像质量，范围为0-100，默认值为95
    - cv2.IMWRITE_PNG_COMPRESSION：PNG图像压缩级别，范围为0-9，默认值为3
    - cv2.IMWRITE_PXM_BINARY：PPM/PGM/PBM图像格式，默认值为False

```python showLineNumbers
import cv2
path= "10.jpg"
img = cv2.imread(path)
cv2.imwrite('new_img.jpg',img, [cv2.IMWRITE_JPEG_QUALITY, 100])
```

### 图像显示、等待按键、关闭窗口

cv2.imshow函数签名：`cv2.imshow(winname, img)`

参数说明：

- `winname`：窗口名称
- `img`：要显示的图像对象

cv2.waitKey函数签名：`cv2.waitKey([delay]) -> retval`

参数说明：

- `delay`：等待时间，单位为毫秒。当值为0时，表示无限等待。

返回值：

- 返回按键的ASCII码<Highlight>（大小写敏感）</Highlight>，如果到时间没有按键按下，则返回-1。

注意：
- <Highlight>如果设置了中文输入法，键盘的捕获会被输入法占用，导致无法正常等待按键按下。</Highlight>
- <Highlight>如果弹出多个相同名称的窗口，只会显示一个窗口，窗口内的图像内容会被覆盖。</Highlight>

上面两个函数是成对出现的，`cv2.imshow`用于显示图像，`cv2.waitKey`用于等待按键按下或者到时间自动关闭窗口。

下面两个函数都表示关闭窗口，区别在于`destroyWindow`是关闭指定窗口，而`destroyAllWindows`是关闭所有窗口。

destroyWindow函数签名：`cv2.destroyWindow(winname)`
参数说明：
- `winname`：要关闭的窗口名称

destroyAllWindows函数签名：`cv2.destroyAllWindows()`

```python showLineNumbers
import cv2
path= "10.jpg"
img = cv2.imread(path)
# 显示图片, 参数：img: 图像对象, 'Image': 窗口名称
# 如果窗口名称重复，则不会创建新的窗口，而是将图像显示在已有的窗口中
cv2.imshow('Image', img)
# 等待按键按下，0表示无限等待，其他数字表示等待时间（毫秒）
# 这个方法会阻塞程序，直到按键按下，返回值为按键的ASCII码。如果设置了中文输入法，键盘的捕获会被输入法占用，导致无法正常等待按键按下。
key = cv2.waitKey(0)    
# 如果按键为q，则退出
if key == ord('q'):
    # 关闭指定窗口
    cv2.destroyWindow('Image') 
# 关闭所有窗口
cv2.destroyAllWindows()
```

## 图像绘制

### 绘制直线、矩形

- `line`函数签名：`cv2.line(img, pt1, pt2, color, thickness, lineType, shift)`
- `rectangle`函数签名：`cv2.rectangle(img, pt1, pt2, color, thickness, lineType, shift)`

参数说明：

- `img`：图像对象
- `pt1`：起点坐标
- `pt2`：终点坐标
- `color`：颜色
- `thickness`：线宽
- `lineType`：线型
- `shift`：位移，默认为0，表示坐标是整数，如果大于1，则表示坐标是浮点数，例如shift=2，则表示坐标是浮点数。可用于实现亚像素精度绘图。
- <Highlight>对于矩形来说，`pt1`是左上角，`pt2`是右下角。</Highlight>

### 圆形、椭圆

- `circle`函数签名：`cv2.circle(img, center, radius, color, thickness, lineType, shift)`
- `ellipse`函数签名：`cv2.ellipse(img, center, axes, angle, startAngle, endAngle, color, thickness, lineType, shift)`

参数说明：

- `img`：图像对象
- `center`：圆心坐标
- `radius`：半径
- `axes`：椭圆长轴和短轴长度
- `angle`：椭圆旋转角度
- `startAngle`：椭圆起始角度
- `endAngle`：椭圆结束角度
- `color`：颜色
- `thickness`：线宽
- `lineType`：线型
- `shift`：位移，默认为0，表示坐标是整数，如果大于1，则表示坐标是浮点数，例如shift=2，则表示坐标是浮点数。可用于实现亚像素精度绘图。

### 多边形

polylines函数签名：`cv2.polylines(img, pts, isClosed, color, thickness, lineType, shift)`

参数说明：

- `img`：图像对象
- `pts`：顶点列表
- `isClosed`：是否闭合
- `color`：颜色
- `thickness`：线宽
- `lineType`：线型
- `shift`：位移，默认为0，表示坐标是整数，如果大于1，则表示坐标是浮点数，例如shift=2，则表示坐标是浮点数。可用于实现亚像素精度绘图。

```python showLineNumbers
# 导入库
import cv2
# 读取图片
img = cv2.imread('10.jpg')
# 绘制直线
# 参数：img: 图像对象, (100, 100): 起点坐标, (200, 200): 终点坐标, (0, 0, 255): 颜色, 2: 线宽
cv2.line(img, (100, 100), (200, 200), (0, 0, 255), 2)
# 绘制矩形
# 参数：img: 图像对象, (100, 100): 左上角坐标, (200, 200): 右下角坐标, (0, 0, 255): 颜色, 2: 线宽
cv2.rectangle(img, (100, 100), (200, 200), (0, 0, 255), 2)
# 绘制圆形
# 参数：img: 图像对象, (150, 150): 圆心坐标, 50: 半径, (0, 0, 255): 颜色, 2: 线宽
cv2.circle(img, (150, 150), 50, (0, 0, 255), 2)
# 绘制多边形
# 参数：img: 图像对象, [pts]: 顶点列表, True: 是否闭合, (0, 0, 255): 颜色, 2: 线宽
pts = np.array([[100, 100], [200, 100], [200, 200], [100, 200]])
cv2.polylines(img, [pts], True, (0, 0, 255), 2)
# 绘制椭圆
# 参数：img: 图像对象, (150, 150): 椭圆中心坐标, (100, 50): 椭圆长轴和短轴长度, 0: 椭圆旋转角度, 0: 椭圆起始角度, 360: 椭圆结束角度, (0, 0, 255): 颜色, 2: 线宽
cv2.ellipse(img, (150, 150), (100, 50), 0, 0, 360, (0, 0, 255), 2)
# 显示图片
cv2.imshow('Image', img)
# 等待按键按下
cv2.waitKey(0)
# 关闭所有窗口
cv2.destroyAllWindows()
```

### 绘制文字

函数签名：`cv2.putText(img, text, org, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)`

参数说明：

- `img`：图像对象
- `text`：要绘制的文字
- `org`：文字的左下角坐标
- `fontFace`：字体类型
- `fontScale`：字体缩放比例（大于1时，文字会变大、0~1时，文字会变小，小于0时，文本将倒置）
- `color`：文字颜色
- `thickness`：文字粗细
- `lineType`：线型
- `bottomLeftOrigin`：是否从左下角开始绘制

函数直接作用于图像对象，不需要返回值。

```python showLineNumbers
import cv2

# 读取图片
img = cv2.imread('10.jpg')
# 绘制文字：Hello, World! 位置为(100, 100)，字体为cv2.FONT_HERSHEY_SIMPLEX，字体缩放比例为1，颜色为红色，粗细为2
cv2.putText(img, 'Hello, World!', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
# 显示图片
cv2.imshow('Image', img)
# 展示1秒
cv2.waitKey(1000)
# 关闭所有窗口
cv2.destroyAllWindows()
```

### PIL库绘制中文

cv2的在图片上的绘制语法主要缺陷为无法绘制中文，需要使用PIL库来绘制中文。

字体文件：一种可以把码点转换为像素显示的超大型字典。

```python showLineNumbers
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
# 打开图片
img = Image.open('imgs/img/10.jpg')  # 替换为你的图片路径
# 设置字体（确保路径正确，Windows下常见字体路径如下）
font_path = "simhei.ttf"  # 黑体
font_size = 60
font = ImageFont.truetype(font_path, font_size)
# 要绘制的文字
text = "机器视觉"
# 创建绘图对象
draw = ImageDraw.Draw(img)
# 计算文字尺寸
text_width, text_height = draw.textsize(text, font=font)
# 计算图片中心
img_width, img_height = img.size
x = (img_width - text_width) // 2
y = (img_height - text_height) // 2
# 绘制文字（可设置颜色和描边等）
draw.text((x, y), text, font=font, fill=(255, 0, 0))  # 红色
# 保存或显示图片
img.show()
# img.save('output.jpg')
```

## 图像运算

加减法的前提是两张图片的尺寸相同。

### 图像加法、图像减法

```python showLineNumbers {12,23}
import cv2
import numpy as np
path = "xxx.bmp"
def draw_add(path):
    img = cv2.imread(path)
    img_height, img_width = img.shape[:2]
    # 创建一个全白的mask_img
    mask_img = np.zeros((img_height, img_width, 3), dtype=np.uint8) + 255
    # 在mask_img上写上Showcase
    cv2.putText(mask_img, "Showcase", (img_width//4, img_height//2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 5)
    # 将mask_img和img相加
    img3 = cv2.add(img, mask_img)
    cv2.imwrite(f"add_{path}", img3)

def draw_subtract(path):
    img = cv2.imread(path)
    img_height, img_width = img.shape[:2]
    # 创建一个全白的mask_img
    mask_img = np.zeros((img_height, img_width, 3), dtype=np.uint8) + 255
    # 在mask_img上画一个圆
    cv2.circle(mask_img, (img_width//2, img_height//2), int(min(img_width, img_height)*0.45), (0, 0, 0), -1)
    # 将mask_img和img相减
    img3 = cv2.subtract(img, mask_img)
    cv2.imwrite(f"subtract_{path}", img3)

draw_add(path)
draw_subtract(path)
```

:::info

图像加权cv2.addWeighted

函数签名：`cv2.addWeighted(src1, alpha, src2, beta, gamma) -> dst`

参数说明：

- `src1`：图像1
- `alpha`：图像1的强度，范围为0-1
- `src2`：图像2
- `beta`：图像2的强度，范围为0-1
- `gamma`：偏移量（即图像在加权后，整体增加的值，一般为0）

图像1和图像2的强度不需要合起来等于1，可以大于1，也可以小于1。

```python showLineNumbers
import cv2
import numpy as np

img1 = cv2.imread("green.png")
img2 = cv2.imread("red.png")

img3 = cv2.addWeighted(img1, 1, img2, 1,0)

cv2.imshow("img4", img3)
cv2.waitKey(0)
```
:::

## 基础图像操作

### 图像缩放

函数签名：`cv2.resize(src, dsize, fx, fy, interpolation) -> dst`

参数说明：

- `src`：源图像
- `dsize`：目标图像大小，如果为None，则根据fx和fy计算，传入的是(width, height)
- `fx`：水平缩放比例
- `fy`：垂直缩放比例
- `interpolation`：插值方式，默认值为cv2.INTER_LINEAR:双线性插值


当resize指定的新尺寸大于原尺寸时，会使用插值方式来填充新产生的像素。

```python showLineNumbers
import cv2
import numpy as np

img1 = cv2.imread("xxx.png")
# 固定值缩放
img2 = cv2.resize(img1, (100, 100))
# 按比例缩放
img2 = cv2.resize(img1, dsize = None, fx = 0.5, fy = 0.5)
```

### 拆分与合并通道

拆分通道函数签名：`cv2.split(img) -> list`

合并通道函数签名：`cv2.merge(list) -> img`

参数说明：

- `img`：图像对象

返回值：

- `list`：不同通道的图像对象

```python showLineNumbers
import cv2
import numpy as np

img = cv2.imread("xxx.png")
b, g, r = cv2.split(img)

img2 = cv2.merge([b, g, r])

cv2.imshow("img", img)
cv2.imshow("img2", img2)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 其他操作

```python showLineNumbers
import cv2
import numpy as np

img = cv2.imread("xxx.png")

# 图像翻转
# 0: 上下翻转（垂直翻转）
# 1: 左右翻转（水平翻转）
# -1: 上下左右翻转（垂直水平翻转）
img1 = cv2.flip(img, 0)

# 图像裁剪
roi = (100, 100, 200, 200)
img2 = img[100:300, 100:300]


# 图像平移
# 参数1：原图像
# 参数2：仿射变换矩阵
# 参数3：目标图像大小
width, height = img.shape[:2]
M = np.float32([[1, 0, 100], [0, 1, 100]])
img2 = cv2.warpAffine(img, M, (width, height))

# 图像旋转
# 参数1：中心点
# 参数2：旋转角度
# 参数3：缩放比例
M = cv2.getRotationMatrix2D(center, angle, scale)

# 图像仿射变换
# 参数1：原图像的三个点
# 参数2：目标图像的三个点
# 返回值：仿射变换矩阵
M = cv2.getAffineTransform(pts1, pts2)

# 图像透视变换
# 参数1：原图像的四个点
# 参数2：目标图像的四个点
# 返回值：透视变换矩阵
M = cv2.getPerspectiveTransform(pts1, pts2)

# 图像扩边
# 参数1：原图像
# 参数2：上边框宽度
# 参数3：下边框宽度
# 参数4：左边框宽度
# 参数5：右边框宽度
# 参数6：边框类型
# 参数7：边框颜色
img2 = cv2.copyMakeBorder(img, top, bottom, left, right, borderType, value)

```

## 色彩处理

:::info
科普：什么是HSV？

HSV：相比RGB相比，HSV能更好的表示同个颜色的不同值（饱和度和明度）
- H: 色调，取值范围是0-180，表示颜色
- S: 饱和度，取值范围是0-255，表示颜色的纯度
- V: 明度，取值范围是0-255，表示颜色的亮度
:::


:::info
什么是24位真彩屏？

每个像素点的取值返回是0~255，即在二进制中需要8位来表示（2的8次方）

那么 R G B 三个通道就需要 8 + 8 + 8 = 24 位来表示

难道还有假彩屏？

是的，因为人眼并不能分辨出 255 * 255 * 255 种颜色，所以可以适当的减少一些颜色，也不影响人眼感知

所以就有了<HoverText text="16bit屏幕（单片机常用）" explanation="蓝色：5位 + 绿色：6位 + 红色：5位"/>

:::

### 灰度图

灰度图
适用于图像处理，如边缘检测及其应用：图像分割、轮廓检测
只有1个通道，取值范围是0-255，表示颜色的亮度

```python showLineNumbers
import numpy as np
import cv2

# 方式1 （支持自定义权重）
img = cv2.imread("xxx.png")
B,G,R = cv2.split(img)
gray = R*0.299 + G*0.587 + B*0.114
gray = gray.astype(np.uint8)

# 方式2 (最简单，最常用)
gray = cv2.imread("xxx.png",0)

# 方式3 （可以转化为各种色彩空间）
img = cv2.imread("xxx.png")
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)


cv2.imshow("gray",gray)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 二值化图

二值化图
适用于图像压缩
只有1个通道，取值范围是0或1

#### 人为设置阈值法（固定阈值法）

在这种方法中，我们人为设定一个阈值，比如 取 255 的中间值 127。 大于这个值则取1,小于等于这个值则取0

在 Python 中，这种除法运算后向下取整的操作可以表示为 255 // 2，也等价于 int(255/2)。

存在的问题：

这种方法的主要问题在于，它并不能适应所有类型的图像。

例如，对于一张整体偏暗的照片，大部分像素值可能都会低于 127，因此二值化后的图像几乎全黑。

同样，对于一张整体偏亮的照片，大部分像素值可能都会高于 127，因此二值化后的图像几乎全白。

#### 全局平均值法

为了解决上述问题，我们可以使用一种被称为"平均值法"的优化方法。在这种方法中，我们不再使用固定的阈值，而是计算图像本身的平均像素值，并用这个值作为阈值。

优点：

这种方法可以更好地适应不同亮度的图像，因为它根据图像的实际像素值分布来确定阈值，而不是简单地使用固定的阈值。

对于那些整体偏暗或偏亮的图像，使用平均值法可以得到更好的二值化效果。

注意：

尽管平均值法在许多情况下都能得到不错的结果，但它仍然不能解决所有问题。例如，对于那些既有很亮的区域又有很暗的区域的图像，平均值法可能无法得到理想的二值化效果。在这种情况下，可能需要使用更复杂的方法，如自适应阈值法或 Otsu's 方法等。

#### 自适应阈值法

自适应阈值法是一种更为复杂的二值化方法，它不是使用一个全局阈值，而是为图像中的每一个小区域计算一个阈值。这意味着在图像的不同部分可能会使用不同的阈值，使得二值化的效果更好。

自适应阈值法的基本步骤如下：

将图像分割为许多小区域。 对于每一个小区域，计算其像素值的平均值或中值，并将这个值作为该区域的阈值。 对每一个小区域进行二值化。 这种方法对于那些局部亮度变化大的图像特别有效，但是计算量比较大。。

该方法常常用于自动驾驶，可以根据不同的光照条件，自动调整阈值。

#### Otsu's 方法

Otsu's 方法是一种自动确定阈值的方法，它通过使得二值化后的图像的类间方差最大化来确定最佳阈值。这种方法的基本步骤如下：

1. 对图像的灰度直方图进行归一化，使其成为一个概率分布。
2. 对于每一个可能的阈值，计算类间方差。
3. 选择使得类间方差最大的阈值作为最佳阈值。

Otsu's 方法对于那些有明显的双峰灰度直方图的图像特别有效，但是对于灰度分布比较均匀的图像可能效果不佳。

:::info
什么是直方图

横坐标：表示的是像素的数值，最左边是0，最右边是255

纵坐标：表示的是像素的个数

常用于观察图片的像素分布
:::

:::info
归一化（Normalization）是一种常见的数据预处理技术

用于改变数据的范围以使其落在一个特定的区间,通常是[0,1]或者[-1,1]。

归一化的目的是消除数据量纲和尺度的影响，使得不同尺度或单位的数据可以在同一水平上进行比较或处理。
:::

Otsu's 方法的目标就是找到一个阈值，使得类间方差最大。这个阈值就是最佳的二值化阈值。这种方法假设图像包含两类像素（即前景和背景），且这两类像素的灰度值分布是双峰的。在这种情况下，类间方差最大的阈值可以很好地分割这两类像素。 (t)最大。这个阈值就是最佳的二值化阈值。这种方法假设图像包含两类像素（即前景和背景），且这两类像素的灰度值分布是双峰的。在这种情况下，类间方差最大的阈值可以很好地分割这两类像素。

缺点：计算量都比较大，特别是对于大图像或高分辨率的图像。因此，在实际使用时需要考虑到计算效率和内存使用的问题。


```python showLineNumbers
# 用于数据计算
import numpy as np
# 用于图像读取与处理
import cv2
# 用于图像显示
import matplotlib.pyplot as plt

class ImageThresholding:
    def __init__(self, image_path):
        # 直接读取为灰度图
        self.image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    def threshold_fixed(self, threshold=127):
        """使用OpenCV的固定阈值二值化"""
        _, binary_image = cv2.threshold(self.image, threshold, 255, cv2.THRESH_BINARY)
        return (binary_image / 255).astype(int)  # 转换为0和1的值

    def threshold_mean(self):
        """使用OpenCV的自适应均值阈值二值化"""
        binary_image = cv2.adaptiveThreshold(self.image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, 
                                           cv2.THRESH_BINARY, 11, 2)
        return (binary_image / 255).astype(int)  # 转换为0和1的值

    def threshold_adaptive(self, window_size=11):
        """使用OpenCV的自适应高斯阈值二值化"""
        # 确保window_size是奇数
        if window_size % 2 == 0:
            window_size += 1
        binary_image = cv2.adaptiveThreshold(self.image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                           cv2.THRESH_BINARY, window_size, 2)
        return (binary_image / 255).astype(int)  # 转换为0和1的值

    def threshold_otsu(self):
        """使用OpenCV的Otsu自动阈值二值化"""
        _, binary_image = cv2.threshold(self.image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        return (binary_image / 255).astype(int)  # 转换为0和1的值

    def show_image(self, image, title):
        
        plt.imshow(image, cmap='gray')# 显示灰度图
        plt.title(title)# 设置标题
        plt.axis('off')# 不要显示坐标轴
        plt.show()

if __name__ == "__main__":
    thresholding = ImageThresholding('xxx.bmp')
    thresholding.show_image(thresholding.threshold_fixed(), 'Fixed Thresholding')
    thresholding.show_image(thresholding.threshold_mean(), 'Mean Thresholding')
    thresholding.show_image(thresholding.threshold_adaptive(), 'Adaptive Thresholding')
    thresholding.show_image(thresholding.threshold_otsu(), 'Otsu Thresholding')
```

除了上述的方法之外，还有许多其他的二值化方法，每种方法都有其适用的场景和优缺点。

以下是一些常见的二值化方法：

双峰法（Bimodal method）：这种方法假设图像的直方图是双峰的，即有两个主要的亮度级别（通常对应于对象和背景）。阈值被设置为这两个峰值之间的最低点。

最小误差法（Minimum error method）：这种方法假设像素的灰度值来自两个具有相同方差的高斯分布。阈值被设置为最小化两个分布之间的误差的值。

最大熵法（Maximum entropy method）：这种方法选择使得二值化后的两个类（即，阈值以上和以下的像素）的熵之和最大的阈值。

Kittler-Illingworth 最小误差法：这种方法是最小误差法的一个改进版本，它可以处理来自不同高斯分布（即，具有不同方差）的像素。

ISODATA 算法：这是一种迭代的方法，它开始于图像的平均灰度值，然后迭代地计算两个类的平均值，直到阈值稳定。

Niblack 方法：这是一种局部阈值选择方法，它根据每个像素周围的像素的平均值和标准差来计算阈值。

Sauvola 方法：这是 Niblack 方法的一个改进版本，它引入了一个新的参数来处理不同对比度的图像。

多阈值方法：这些方法不是选择一个阈值，而是选择多个阈值，将像素分割成多个类。这对于一些应用可能会很有用，例如在处理具有多个亮度级别的对象的图像时。


## 形态学处理

### 膨胀和腐蚀

膨胀函数签名：`cv2.dilate(img,kernel,iterations=5)`

腐蚀函数签名：`cv2.erode(img,kernel,iterations=5)`

参数：

- img：输入图像
- kernel：膨胀和腐蚀的核
- iterations：膨胀和腐蚀的迭代次数

膨胀工作原理：类似卷积操作，将核覆盖在图像上，如果核的中心点在图像的范围内，则将核的中心点替换为核的最大值。

腐蚀工作原理与膨胀相反，将核覆盖在图像上，如果核的中心点在图像的范围内，则将核的中心点替换为核的最小值。


```python showLineNumbers
import cv2
import numpy as np
img = cv2.imread("dt2.png")
# 膨胀和腐蚀的操作
kernel = np.ones((3,3),np.uint8)
# 腐蚀
erode = cv2.erode(img,kernel,iterations=5)
# 膨胀
dilate = cv2.dilate(img,kernel,iterations=5)
cv2.imshow("img",img)
cv2.imshow("dilate",dilate)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

:::info
- 开运算: 先腐蚀后膨胀，用于去除图像中的小噪声
- 闭运算: 先膨胀后腐蚀，用于填充图像中的小孔洞
- 形态学梯度: 膨胀 - 腐蚀，用于提取图像中的边缘
- 顶帽: 原图 - 开运算，用于提取图像中的小噪声
- 黑帽: 闭运算 - 原图，用于填充图像中的小孔洞
:::


### 模糊

模糊的原理：让像素点的混在一起：即每个像素点不再是自己，而是自己与周围像素点的混合值。

常见的有：

- 高斯模糊：`cv2.GaussianBlur`
- 中值滤波：`cv2.medianBlur`
- Box滤波：`cv2.boxFilter`
- 均值滤波：`cv2.blur`（Box滤波的归一化版本）
- 双边滤波：`cv2.bilateralFilter`
- 矩阵卷积（自定义卷积核）：`cv2.filter2D`

```python showLineNumbers
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
import cv2

# 设置中文字体
# 替换为你系统中支持中文的字体路径(windows)
font_path = r'C:\Windows\Fonts\simhei.ttf'  
# mac（如果有的话）
# font_path = '/System/Library/Fonts/STHeiti Light.ttc' 
font_prop = FontProperties(fname=font_path)

# 读取灰度图像
image = np.array(cv2.imread('xxx.bmp',cv2.IMREAD_GRAYSCALE))

# 定义卷积核
kernels = {
    '水平边缘': np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]]),
    '垂直边缘': np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]),
    'Sobel水平': np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),
    'Sobel垂直': np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]),
    '拉普拉斯': np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]),
    '锐化': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),
    '高斯模糊3x3': np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16,
    '边缘增强': np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]),
    'Box滤波': np.array([[2, 2, 2], [2, 2, 2], [2, 2, 2]]) / 9
    '均值滤波': np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9,
}

# 使用NumPy实现卷积操作
def convolve2d(image, kernel):
    # 获取图像和卷积核的尺寸
    i_height, i_width = image.shape
    k_height, k_width = kernel.shape
    
    # 计算输出图像的尺寸
    o_height = i_height - k_height + 1
    o_width = i_width - k_width + 1
    
    # 创建输出图像
    output = np.zeros((o_height, o_width))
    
    # 执行卷积操作
    for y in range(o_height):
        for x in range(o_width):
            # 提取图像区域
            region = image[y:y+k_height, x:x+k_width]
            # 计算卷积值
            output[y, x] = np.sum(region * kernel)
    
    return output

# 应用卷积核
results = {}
for name, kernel in kernels.items():
    # 为了处理边界，先对图像进行填充
    if kernel.shape[0] == 5:  # 对于5x5卷积核
        pad_width = 2
    else:  # 对于3x3卷积核
        pad_width = 1
    
    padded_image = np.pad(image, pad_width, mode='constant')
    filtered_image = convolve2d(padded_image, kernel)
    
    # 归一化处理，确保像素值在有效范围内
    filtered_image = np.clip(filtered_image, 0, 255).astype(np.uint8)
    results[name] = filtered_image

# 显示结果
plt.figure(figsize=(15, 8))
for i, (name, result) in enumerate(results.items()):
    plt.subplot(3, 4, i + 1)
    plt.imshow(result, cmap='gray')
    plt.title(name, fontproperties=font_prop)
    plt.axis('off')

plt.tight_layout()
plt.show()
```
## 边缘与轮廓

### 边缘检测cv2.Canny
### 获取轮廓cv2.findContours
### 轮廓属性cv2.contourArea、cv2.arcLength

```python showLineNumbers
import cv2
img = cv2.imread("xxx.png")
# 边缘检测
# 低阈值、高阈值：
# 强边缘：梯度值 > 高阈值 → 确定保留
# 弱边缘：低阈值 < 梯度值 < 高阈值 → 条件保留
# 噪声：梯度值 < 低阈值 → 丢弃（不保留）
canny = cv2.Canny(img,threshold1=100,threshold2=200)

# 轮廓检测
contours,hierarchy = cv2.findContours(canny,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)

# 轮廓的面积
area = cv2.contourArea(contours[0])
# 轮廓的周长
perimeter = cv2.arcLength(contours[0],True)

max_area = max([cv2.contourArea(contour) for contour in contours])
for contour in contours:
    if cv2.contourArea(contour) >= max_area:
        # 绘制轮廓
        cv2.drawContours(img,contour,-1,(0,0,255),1)

cv2.imshow("img",img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

## 动态图像

### 视频读取与显示

```python showLineNumbers
# cv2.VideoCapture(参数)：参数可以是整数、字符串、流媒体

# 整数:表示摄像头的编号
# 0:表示默认摄像头
# 1:表示第二个摄像头

# 字符串:表示视频文件的路径（绝对相对都可以）：1.mp4

# 流媒体:表示视频流： http://192.168.1.100:8080

cap = cv2.VideoCapture(0) # 摄像头的语柄
if not cap.isOpened():
    print("Error: Could not open video.")
    cap.release() # 释放摄像头
while True:
    ret,frame = cap.read() # 读取视频帧
    # ret:表示是否读取成功（True/False）
    # frame:表示读取到的视频帧数据（numpy数组）
    if not ret:
        print("Error: Could not read frame.")
        break
    cv2.imshow("frame",frame) # 显示视频帧。同个窗口名称，会覆盖窗口内容，而不是新开窗口。
    if cv2.waitKey(1) == ord('q'): # 按q键退出循环
        break
cap.release() # 释放摄像头
cv2.destroyAllWindows() # 关闭所有窗口
```

### 视频保存

函数签名：`cv2.VideoWriter(filename, fourcc, fps, frameSize)`

参数说明：

- filename：视频文件名
- fourcc：视频编码格式
- fps：帧率
- frameSize：帧大小

```python showLineNumbers {16,18,31,35}
import cv2
import numpy as np
# cv2.VideoCapture(参数)：参数可以是整数、字符串、流媒体

# 整数:表示摄像头的编号
# 0:表示默认摄像头
# 1:表示第二个摄像头

# 字符串:表示视频文件的路径（绝对相对都可以）：1.mp4

# 流媒体:表示视频流：rtsp://192.168.1.100:8554/test 或者 http://192.168.1.100:8080

cap = cv2.VideoCapture(0) # 摄像头的语柄

# 视频的编码格式
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
# 视频的输出路径
out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (640,480))


if not cap.isOpened():
    print("Error: Could not open video.")
    cap.release() # 释放摄像头
while True:
    ret,frame = cap.read() # 读取视频帧
    # ret:表示是否读取成功（True/False）
    # frame:表示读取到的视频帧数据（numpy数组）
    if not ret:
        print("Error: Could not read frame.")
        break
    out.write(frame) # 写入视频帧
    cv2.imshow("frame",frame) # 显示视频帧。同个窗口名称，会覆盖窗口内容，而不是新开窗口。
    if cv2.waitKey(1) == ord('q'): # 按q键退出循环
        break
out.release() # 释放视频
cap.release() # 释放摄像头
cv2.destroyAllWindows() # 关闭所有窗口
```


## 案例-人脸识别：录入并识别不同人脸

- 这段程序首先会读取摄像头，并自动截取一定数量的人脸用作训练。
- 然后将截取的人脸进行训练，生成一个训练模型。
- 最后通过摄像头实时识别人脸

使用下方代码时，需要保证当前文件夹存在以下内容。（如必须在非当前目录执行，请替换相关路径为绝对路径，你可能需要根据自己的摄像头修改代码中的CID = 0的值）

- `dataSet`文件夹  
如不存在可自行创建一个空文件夹，注意大小写敏感。

- `haarcascade_frontalface_default.xml`文件 可以通过 `everthing` 搜索 ，移动到当前目录。


```python showLineNumbers
import os
import cv2
import numpy as np

# 摄像头被分配到的设备ID，window通常为0，linux通常为1，AIBox通常为9~13
CID = 0


# 输入人脸,id为人脸对应的id，同个id的人脸会被识别为同一个人
def get_face(id="1"):
    faceDetect = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
    cam = cv2.VideoCapture(CID)
    sampleNum = 0
    while True:
        ret, img = cam.read()
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = faceDetect.detectMultiScale(gray, 1.3, 5)
        for x, y, w, h in faces:
            sampleNum = sampleNum + 1
            cv2.imwrite(
                "dataSet/User." + str(id) + "." + str(sampleNum) + ".png",
                gray[y : y + h, x : x + w],
            )
            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)
            cv2.waitKey(100)
        cv2.imshow("Face", img)
        cv2.waitKey(1)
        if sampleNum > 20:
            break
    cam.release()
    cv2.destroyAllWindows()


# 训练数据
def trainer_face(path="dataSet"):
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]
    faces = []
    IDs = []
    for imagePath in imagePaths:
        faceImg = cv2.imread(imagePath,0)
        faceNp = np.array(faceImg, "uint8")
        ID = int(os.path.split(imagePath)[-1].split(".")[1])
        faces.append(faceNp)
        IDs.append(ID)
        cv2.imshow("training", faceNp)
        cv2.waitKey(10)
    recognizer.train(faces, np.array(IDs))
    recognizer.save("trainningData.yml")
    cv2.destroyAllWindows()


# 识别人脸
def recognizer(labels={"p1": 1, "p2": 2}):
    # 加载人脸识别器
    face_cascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

    # 加载已训练的人脸识别模型
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.read("trainningData.yml")

    # 初始化摄像头
    cap = cv2.VideoCapture(CID)
    font = cv2.FONT_HERSHEY_COMPLEX_SMALL
    while True:
        ret, frame = cap.read()
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # 检测人脸
        faces = face_cascade.detectMultiScale(
            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)
        )

        rgb_color = (0, 0, 0)
        for x, y, w, h in faces:
            # 识别人脸
            id, confidence = recognizer.predict(gray[y : y + h, x : x + w])
            person = ""
            if confidence < 100:
                for name, label in labels.items():
                    if label == id:
                        person = name
                        break
                confidence = int(100 - confidence)
                if int(confidence) > 40:
                    rgb_color = (0, 255, 0)  # 绿色
                    person = f"{person}: {confidence}%"

                elif 0 < int(confidence) < 40:
                    rgb_color = (255, 0, 0)  # 红色
                    person = "unkonw"
            cv2.putText(
                frame,
                str(person),
                (x, y + h),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (0, 0, 255),
                2,
            )  # 更新为cv2.putText()
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.imshow("Face Recognition", frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    get_face(id="1")
    trainer_face(path="dataSet")
    recognizer()
```