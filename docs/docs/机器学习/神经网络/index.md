---
sidebar_position: 3
title: ğŸš§ç¥ç»ç½‘ç»œå…¥é—¨
---

## skorch

è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å­¦ä¹ äº† scikit-learn çš„å¾ˆå¤šç®—æ³•ã€‚å®Œæˆäº†ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ä»»åŠ¡ã€‚

ä½†æ˜¯ï¼Œsklearnæœ¬èº«ä¸æ”¯æŒGPUåŠ é€Ÿã€‚é‡åˆ°æ›´å¤æ‚çš„ä»»åŠ¡ï¼Œéœ€è¦ä½¿ç”¨ç¥ç»ç½‘ç»œå¹¶è°ƒç”¨GPUæ¥å®Œæˆã€‚

skorch æ˜¯ä¸€ä¸ªåŸºäº PyTorch çš„ç¥ç»ç½‘ç»œåº“ï¼Œæä¾›äº† scikit-learn é£æ ¼çš„ APIã€‚å®ƒå°† PyTorch çš„çµæ´»æ€§ä¸ scikit-learn çš„æ˜“ç”¨æ€§ç›¸ç»“åˆï¼Œä½¿å¾—ç¥ç»ç½‘ç»œçš„è®­ç»ƒå’Œè¯„ä¼°å˜å¾—æ›´åŠ ç®€å•å’Œé«˜æ•ˆã€‚æ”¯æŒGPUåŠ é€Ÿã€‚

å®ƒå¯ä»¥è®©ä½ ä»…ä»…æ›¿æ¢ sklearn çš„æ¨¡å‹ä¸º pytorch çš„æ¨¡å‹ï¼Œä¸æ”¹å˜å…¶ä»–ä»£ç ã€‚ä½œä¸ºè¡”æ¥ pytorch å’Œ sklearn çš„æ¡¥æ¢ã€‚

skorch çš„å®‰è£…éå¸¸ç®€å•ï¼Œåªéœ€è¦ä½¿ç”¨ pip å®‰è£…å³å¯ã€‚

```bash
pip install skorch
```

### ç®€å•ç¤ºä¾‹

```python showLineNumbers
# å¯¼å…¥å¿…è¦çš„åº“
import numpy as np
from sklearn import datasets
from torch import nn
from skorch import NeuralNetClassifier
from sklearn.model_selection import train_test_split
import time
from sklearn.linear_model import LinearRegression
import torch

# åŠ è½½æ•°æ®é›†
digits = datasets.load_digits()
# è·å–ç‰¹å¾å’Œç›®æ ‡å˜é‡
X = digits.data.astype(np.float32)  # è½¬æ¢ä¸ºfloat32ç±»å‹
y = digits.target.astype(np.int64)  # ç›®æ ‡å˜é‡è½¬æ¢ä¸ºint64

# ä¿®æ”¹åçš„ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰
class MyModule(nn.Module):
    def __init__(self, num_units=256, nonlin=nn.ReLU()):  # å¢åŠ éšè—å•å…ƒæ•°
        super().__init__()
        self.dense0 = nn.Linear(64, num_units)  # ä¿®æ­£è¾“å…¥ç»´åº¦ä¸º64ï¼ˆ8x8å›¾åƒï¼‰
        self.bn0 = nn.BatchNorm1d(num_units)     # æ·»åŠ æ‰¹é‡å½’ä¸€åŒ–
        self.nonlin = nonlin
        self.dropout = nn.Dropout(0.3)           # è°ƒæ•´dropoutæ¯”ä¾‹
        self.dense1 = nn.Linear(num_units, num_units//2)  # æ–°å¢éšè—å±‚
        self.dense2 = nn.Linear(num_units//2, num_units//4)
        self.output = nn.Linear(num_units//4, 10)
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, X, **kwargs):
        X = self.nonlin(self.bn0(self.dense0(X)))
        X = self.dropout(X)
        X = self.nonlin(self.dense1(X))
        X = self.nonlin(self.dense2(X))
        X = self.softmax(self.output(X))
        return X

# ä¿®æ”¹åçš„ç¥ç»ç½‘ç»œé…ç½®
net = NeuralNetClassifier(
    MyModule,
    max_epochs=20,            # å¢åŠ è®­ç»ƒè½®æ¬¡
    lr=0.0005,                # è°ƒæ•´å­¦ä¹ ç‡
    optimizer=torch.optim.AdamW,  # ä½¿ç”¨æ›´å¥½çš„ä¼˜åŒ–å™¨
    optimizer__weight_decay=0.001,  # æ·»åŠ æƒé‡è¡°å‡
    iterator_train__shuffle=True,
    device='cuda',
)

# ä¿®æ”¹ä¸ºçº¿æ€§å›å½’æ¨¡å‹ï¼ˆæ³¨æ„è¿™æ˜¯å›å½’æ¨¡å‹ï¼Œéœ€è¦è½¬æ¢é¢„æµ‹ç»“æœä¸ºåˆ†ç±»ï¼‰
clf = LinearRegression()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# ä¿®æ”¹æ ‡å‡†åŒ–éƒ¨åˆ†
X_train = (X_train / 16.0).astype(np.float32)  # ä¿æŒfloat32ç±»å‹
X_test = (X_test / 16.0).astype(np.float32)

# ä¿å­˜åŸå§‹è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
X_train_orig = X_train.copy()
y_train_orig = y_train.copy()
X_test_orig = X_test.copy()  # æ–°å¢æµ‹è¯•é›†å¤‡ä»½

# åŸå§‹æ•°æ®ã€10å€æ•°æ®ã€100å€æ•°æ®
for i in range(3):
    # é€šè¿‡å¤åˆ¶æ•°æ®å¢åŠ æ ·æœ¬é‡
    multiplier = 10 ** i
    X_train = np.tile(X_train_orig, (multiplier, 1))
    y_train = np.tile(y_train_orig, multiplier)
    X_test = X_test_orig.copy()  # ä¿æŒæµ‹è¯•é›†ä¸å˜
    
    len_data = len(X_train)
    for model in [net, clf]:
        # å¯¹æ¯”sklearnå’Œskorchçš„è®­ç»ƒæ—¶é—´
        start_time = time.time()
        net.fit(X_train, y_train)
        accuracy = net.score(X_test, y_test)
        end_time = time.time() - start_time
        print(f"{len_data}æ¡æ•°æ®ä¸‹ï¼Œ{model.__class__.__name__}è®­ç»ƒæ—¶é—´: {end_time:.2f}ç§’ï¼Œå‡†ç¡®ç‡: {accuracy:.2f}")
'''
1257æ¡æ•°æ®ä¸‹ï¼ŒNeuralNetClassifierè®­ç»ƒæ—¶é—´: 1.26ç§’ï¼Œå‡†ç¡®ç‡: 0.98
1257æ¡æ•°æ®ä¸‹ï¼ŒLinearRegressionè®­ç»ƒæ—¶é—´: 0.33ç§’ï¼Œå‡†ç¡®ç‡: 0.97

12570æ¡æ•°æ®ä¸‹ï¼ŒNeuralNetClassifierè®­ç»ƒæ—¶é—´: 2.91ç§’ï¼Œå‡†ç¡®ç‡: 0.98
12570æ¡æ•°æ®ä¸‹ï¼ŒLinearRegressionè®­ç»ƒæ—¶é—´: 2.93ç§’ï¼Œå‡†ç¡®ç‡: 0.98

125700æ¡æ•°æ®ä¸‹ï¼ŒNeuralNetClassifierè®­ç»ƒæ—¶é—´: 32.05ç§’ï¼Œå‡†ç¡®ç‡: 0.99
125700æ¡æ•°æ®ä¸‹ï¼ŒLinearRegressionè®­ç»ƒæ—¶é—´: 32.31ç§’ï¼Œå‡†ç¡®ç‡: 0.99
'''
```

æ˜¾è€Œæ˜“è§ï¼Œåœ¨å¤„ç†æ›´å¤šæ•°æ®æ—¶ï¼Œskorch çš„è®­ç»ƒæ—¶é—´å°äº sklearn çš„è®­ç»ƒæ—¶é—´ã€‚æ•°æ®è¶Šå¤šï¼Œskorch çš„ä¼˜åŠ¿è¶Šæ˜æ˜¾ã€‚

æ¥ä¸‹æ¥ï¼Œä½ å¯ä»¥ä½¿ç”¨ skorch æ¥å¤ç°æ›´å¤šä¹‹å‰çš„é¡¹ç›®ï¼ŒåŒæ—¶ç†Ÿæ‚‰Pytorchçš„ç”¨æ³•ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬ä¼šå¼€å§‹ä½¿ç”¨pytorchæ¥å®Œæˆæ›´å¤šå¤æ‚å’Œæœ‰è¶£çš„ä»»åŠ¡ã€‚


## PyTorch

PyTorch å¯ä»¥åˆ©ç”¨è®¡ç®—åŠ é€Ÿè®¾å¤‡ï¼ˆä¾‹å¦‚GPUã€NPUï¼‰ï¼Œä¸ºäº†è¾¾æˆè¿™ä¸€ç›®çš„ï¼ŒPyTorch çš„å®‰è£…ä¼šç»‘å®šå¯¹åº”çš„cudaç‰ˆæœ¬ï¼ŒPyTorch ä½¿ç”¨ cuda çš„æ¥å£æ¥æ“ä½œåº•å±‚ç¡¬ä»¶ã€‚

:::info

**CUDA**ï¼šNVIDIA ä¸“ä¸ºè‡ªå®¶ GPU è®¾è®¡çš„ C++ å¹¶è¡Œè®¡ç®—æ¡†æ¶ï¼Œå…¶è¿è¡Œä¾èµ–äº NVIDIA æ˜¾å¡é©±åŠ¨ç¨‹åºã€‚å®ƒå…è®¸å¼€å‘è€…åˆ©ç”¨ GPU å¼ºå¤§çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›åŠ é€Ÿå„ç±»è®¡ç®—å¯†é›†å‹ä»»åŠ¡ã€‚

**cuDNN**ï¼šä¸“é—¨ä¸ºæ·±åº¦å­¦ä¹ è®¡ç®—ä¼˜åŒ–çš„é«˜æ€§èƒ½ç¥ç»ç½‘ç»œåº“ï¼Œæä¾›äº†é«˜åº¦ä¼˜åŒ–çš„å®ç°ï¼Œç”¨äºå¸¸è§æ·±åº¦å­¦ä¹ æ“ä½œå¦‚å·ç§¯ã€æ± åŒ–ã€å½’ä¸€åŒ–ç­‰ã€‚

**CUDA Toolkit (NVIDIA å®˜æ–¹ç‰ˆ)**ï¼šå®Œæ•´çš„ CUDA å¼€å‘ç¯å¢ƒï¼ŒåŒ…å«ï¼š
- NVIDIA æ˜¾å¡é©±åŠ¨ç¨‹åº
- å®Œæ•´çš„ CUDA å¼€å‘å·¥å…·é“¾ï¼ˆç¼–è¯‘å™¨ã€IDEã€è°ƒè¯•å™¨ç­‰ï¼‰
- å„ç§ CUDA åŠ é€Ÿåº“åŠå…¶å¤´æ–‡ä»¶
- æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç 

**CUDA Toolkit (PyTorch ç‰ˆ)**ï¼šç²¾ç®€ç‰ˆ CUDA å·¥å…·åŒ…ï¼Œä¸»è¦åŒ…å«ï¼š
- è¿è¡Œ CUDA åŠŸèƒ½æ‰€éœ€çš„æ ¸å¿ƒåŠ¨æ€é“¾æ¥åº“
- ä¸åŒ…å«é©±åŠ¨ç¨‹åºã€å¼€å‘å·¥å…·åŠå®Œæ•´æ–‡æ¡£
- ä¸“ä¸ºæ”¯æŒ PyTorch ç­‰æ¡†æ¶çš„ CUDA åŠŸèƒ½è€Œè®¾è®¡

**NVCC**ï¼šNVIDIA CUDA ç¼–è¯‘å™¨ï¼Œæ˜¯ CUDA Toolkit çš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£å°† CUDA ä»£ç ç¼–è¯‘ä¸ºå¯åœ¨ NVIDIA GPU ä¸Šæ‰§è¡Œçš„äºŒè¿›åˆ¶ä»£ç ã€‚
:::



### PyTorch æ•°æ®é›†

PyTorch ä¹Ÿæä¾›äº†ä¸€äº›å†…ç½®çš„æ•°æ®é›†ç±»æ¥åŠ è½½å¸¸ç”¨çš„æ•°æ®é›†ï¼Œå¦‚å›¾åƒã€æ–‡æœ¬ç­‰ã€‚æ­¤å¤–ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ç¬¬ä¸‰æ–¹åº“æ¥åŠ è½½è‡ªå®šä¹‰çš„æ•°æ®é›†ã€‚

è¿™äº›æ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯å¯ä»¥åœ¨ PyTorch å®˜æ–¹æ–‡æ¡£ä¸­æ‰¾åˆ°ã€‚

è¿™äº›æ•°æ®é›†åŒ…æ‹¬äº†å„ç§ç±»å‹çš„æ•°æ®ï¼Œå¦‚å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ç­‰ï¼Œå¯ä»¥ç”¨äºå„ç§ä»»åŠ¡ï¼Œå¦‚åˆ†ç±»ã€å›å½’ã€èšç±»ç­‰ã€‚

| æ•°æ®é›†åç§°    | åŠ è½½æ–¹æ³•                         | æ¨¡å‹ç±»å‹ | æ•°æ®å¤§å°(æ ·æœ¬æ•°\*ç‰¹å¾æ•°) |
| ------------- | -------------------------------- | -------- | ------------------------ |
| MNIST         | torchvision.datasets.MNIST       | åˆ†ç±»     | 70000\*784               |
| CIFAR-10      | torchvision.datasets.CIFAR10    | åˆ†ç±»     | 60000\*3072              |
| Fashion MNIST | torchvision.datasets.FashionMNIST| åˆ†ç±»     | 70000\*784               |

```python
import torchvision.datasets as datasets
# åŠ è½½æ•°æ®é›†
train_dataset = datasets.MNIST(root='./data', train=True, download=True)
test_dataset = datasets.MNIST(root='./data', train=False, download=True)
```

### è‡ªå®šä¹‰æ•°æ®ç”Ÿæˆå™¨

ä¸ TensorFlow ç±»ä¼¼ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ PyTorch æ¥ç”Ÿæˆè‡ªå®šä¹‰çš„æ•°æ®é›†ï¼Œä»¥ä¾¿åˆ›å»ºå…·æœ‰ç‰¹å®šå±æ€§çš„æ•°æ®é›†ï¼Œå¦‚ç‰¹å®šçš„åˆ†å¸ƒã€ç‰¹å®šçš„å™ªå£°æ°´å¹³ç­‰ã€‚

```python
import torch
# åˆ›å»ºä¸€ä¸ªçº¿æ€§æ•°æ®é›†
X = torch.rand((1000, 1))
y = 3 * X + 2 + torch.randn((1000, 1))

# åˆ›å»ºä¸€ä¸ªåˆ†ç±»æ•°æ®é›†
X = torch.rand((1000, 2))
y = (torch.sum(X, dim=1) > 1).int()
```

### è‡ªæœ‰æ•°æ®é›†

å¦‚æœä½ æœ‰è‡ªå·±çš„æ•°æ®é›†ï¼Œä½ å¯ä»¥ä½¿ç”¨ PyTorch çš„ `torch.utils.data.Dataset` ç±»æ¥åŠ è½½å’Œé¢„å¤„ç†æ•°æ®ã€‚è¿™ä¸ªç±»æ”¯æŒå„ç§æ•°æ®æ ¼å¼ï¼Œå¦‚ CSVã€å›¾ç‰‡ç­‰ã€‚

```python
from torch.utils.data import Dataset
# è‡ªå®šä¹‰æ•°æ®é›†ç±»
class CustomDataset(Dataset):
    def __init__(self, data_path):
        # ä»æ–‡ä»¶åŠ è½½æ•°æ®
        self.data = torch.load(data_path)
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx]
```


<DocCardList />