"use strict";(self.webpackChunkjiangmiemie=self.webpackChunkjiangmiemie||[]).push([[1908],{78628:(n,e,s)=>{s.r(e),s.d(e,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"\u673a\u5668\u5b66\u4e60/\u5e8f\u5217\u5904\u7406/LSTM","title":"LSTM","description":"LSTM\uff08\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff09\u662f\u6df1\u5ea6\u5b66\u4e60\u4e2d\u6700\u91cd\u8981\u7684\u67b6\u6784\u4e4b\u4e00\u30021997 \u5e74\u7531 Hochreiter \u548c Schmidhuber \u63d0\u51fa\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf RNN \u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u80fd\u591f\u5b66\u4e60\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u3002","source":"@site/docs/docs/\u673a\u5668\u5b66\u4e60/\u5e8f\u5217\u5904\u7406/LSTM.mdx","sourceDirName":"\u673a\u5668\u5b66\u4e60/\u5e8f\u5217\u5904\u7406","slug":"/\u673a\u5668\u5b66\u4e60/\u5e8f\u5217\u5904\u7406/LSTM","permalink":"/docs/\u673a\u5668\u5b66\u4e60/\u5e8f\u5217\u5904\u7406/LSTM","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"title":"LSTM"},"sidebar":"tutorialSidebar","previous":{"title":"\u5e8f\u5217\u5904\u7406","permalink":"/docs/\u673a\u5668\u5b66\u4e60/\u5e8f\u5217\u5904\u7406/"},"next":{"title":"Transformer","permalink":"/docs/\u673a\u5668\u5b66\u4e60/\u5e8f\u5217\u5904\u7406/Transformer"}}');var r=s(74848),t=s(28453);const l={sidebar_position:0,title:"LSTM"},d=void 0,o={},c=[{value:"LSTM \u7b80\u4ecb",id:"lstm-\u7b80\u4ecb",level:2},{value:"RNN \u7684\u95ee\u9898",id:"rnn-\u7684\u95ee\u9898",level:3},{value:"LSTM \u7ed3\u6784",id:"lstm-\u7ed3\u6784",level:2},{value:"\u6838\u5fc3\u7ec4\u4ef6",id:"\u6838\u5fc3\u7ec4\u4ef6",level:3},{value:"\u6570\u5b66\u516c\u5f0f",id:"\u6570\u5b66\u516c\u5f0f",level:3},{value:"\u7b80\u5316\u7406\u89e3\u7248\u672c",id:"\u7b80\u5316\u7406\u89e3\u7248\u672c",level:3},{value:"\u57fa\u7840\u793a\u4f8b",id:"\u57fa\u7840\u793a\u4f8b",level:3},{value:"\u5e8f\u5217\u5230\u5e8f\u5217\uff08Seq2Seq\uff09",id:"\u5e8f\u5217\u5230\u5e8f\u5217seq2seq",level:3},{value:"\u6587\u672c\u60c5\u611f\u5206\u6790",id:"\u6587\u672c\u60c5\u611f\u5206\u6790",level:3},{value:"Bidirectional LSTM\uff08\u53cc\u5411LSTM\uff09",id:"bidirectional-lstm\u53cc\u5411lstm",level:3},{value:"\u8bad\u7ec3\u6280\u5de7",id:"\u8bad\u7ec3\u6280\u5de7",level:2},{value:"\u68af\u5ea6\u88c1\u526a",id:"\u68af\u5ea6\u88c1\u526a",level:3},{value:"\u8fc7\u62df\u5408\u9632\u6b62",id:"\u8fc7\u62df\u5408\u9632\u6b62",level:3},{value:"\u5b66\u4e60\u7387\u8c03\u5ea6",id:"\u5b66\u4e60\u7387\u8c03\u5ea6",level:3},{value:"\u8c03\u8bd5\u6280\u5de7",id:"\u8c03\u8bd5\u6280\u5de7",level:3},{value:"\u6027\u80fd\u4f18\u5316",id:"\u6027\u80fd\u4f18\u5316",level:3}];function a(n){const e={a:"a",admonition:"admonition",br:"br",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(e.admonition,{type:"info",children:[(0,r.jsx)(e.p,{children:"LSTM\uff08\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff09\u662f\u6df1\u5ea6\u5b66\u4e60\u4e2d\u6700\u91cd\u8981\u7684\u67b6\u6784\u4e4b\u4e00\u30021997 \u5e74\u7531 Hochreiter \u548c Schmidhuber \u63d0\u51fa\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf RNN \u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u80fd\u591f\u5b66\u4e60\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u3002"}),(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"LSTM \u7684\u6838\u5fc3\u521b\u65b0\uff1a"})}),(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u95e8\u63a7\u673a\u5236"}),"\uff1a\u901a\u8fc7\u9057\u5fd8\u95e8\u3001\u8f93\u5165\u95e8\u3001\u8f93\u51fa\u95e8\u63a7\u5236\u4fe1\u606f\u6d41\u52a8"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u7ec6\u80de\u72b6\u6001"}),"\uff1a\u4fe1\u606f\u9ad8\u901f\u516c\u8def\uff0c\u8ba9\u68af\u5ea6\u80fd\u591f\u957f\u8ddd\u79bb\u4f20\u64ad"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u957f\u671f\u8bb0\u5fc6"}),"\uff1a\u6709\u6548\u6355\u83b7\u5e8f\u5217\u4e2d\u7684\u957f\u671f\u4f9d\u8d56\u5173\u7cfb"]}),"\n"]}),(0,r.jsx)(e.p,{children:"\u300aLong Short-Term Memory\u300b\u8bba\u6587\u622a\u6b62 2025 \u5e74\uff0c\u8c37\u6b4c\u5b66\u672f\u603b\u5f15\u7528\u6b21\u6570\u6392\u540d\u7b2c 5\uff0c\u662f\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u6700\u5177\u5f71\u54cd\u529b\u7684\u8bba\u6587\u4e4b\u4e00\u3002"}),(0,r.jsx)(e.p,{children:(0,r.jsx)(e.a,{href:"https://www.bioinf.jku.at/publications/older/2604.pdf",children:"\u539f\u59cb\u8bba\u6587\uff1aLong Short-Term Memory (1997)"})})]}),"\n",(0,r.jsx)(e.h2,{id:"lstm-\u7b80\u4ecb",children:"LSTM \u7b80\u4ecb"}),"\n",(0,r.jsx)(e.p,{children:"LSTM\uff08Long Short-Term Memory\uff09\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u67b6\u6784\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf RNN \u5728\u5904\u7406\u957f\u5e8f\u5217\u6570\u636e\u65f6\u7684\u4e24\u5927\u95ee\u9898\uff1a"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u68af\u5ea6\u6d88\u5931\u95ee\u9898"}),"\uff1a\u53cd\u5411\u4f20\u64ad\u65f6\u68af\u5ea6\u9010\u5c42\u8870\u51cf\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5b66\u4e60\u957f\u671f\u4f9d\u8d56"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u957f\u671f\u4f9d\u8d56\u95ee\u9898"}),"\uff1a\u96be\u4ee5\u6355\u83b7\u5e8f\u5217\u4e2d\u76f8\u8ddd\u8f83\u8fdc\u7684\u5143\u7d20\u4e4b\u95f4\u7684\u5173\u7cfb"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"LSTM \u7684\u5e94\u7528\u573a\u666f\uff1a"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08\u6587\u672c\u751f\u6210\u3001\u673a\u5668\u7ffb\u8bd1\u3001\u60c5\u611f\u5206\u6790\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08\u80a1\u7968\u9884\u6d4b\u3001\u5929\u6c14\u9884\u62a5\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u8bed\u97f3\u8bc6\u522b"}),"\n",(0,r.jsx)(e.li,{children:"\u89c6\u9891\u5206\u6790"}),"\n",(0,r.jsx)(e.li,{children:"\u5f02\u5e38\u68c0\u6d4b"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"LSTM \u7684\u5c40\u9650\u6027\uff1a"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u274c \u5bf9\u4e8e\u8d85\u957f\u5e8f\u5217\u4ecd\u6709\u56f0\u96be\uff0c\u5df2\u88ab Transformer \u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8a"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"rnn-\u7684\u95ee\u9898",children:"RNN \u7684\u95ee\u9898"}),"\n",(0,r.jsx)(e.p,{children:"\u4f20\u7edf RNN \u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u5b58\u5728\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff1a"}),"\n",(0,r.jsxs)(e.admonition,{type:"warning",children:[(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"RNN \u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff1a"})}),(0,r.jsx)(e.p,{children:"\u5728\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u68af\u5ea6\u9700\u8981\u901a\u8fc7\u65f6\u95f4\u6b65\u53cd\u5411\u4f20\u64ad\u3002\u5f53\u5e8f\u5217\u5f88\u957f\u65f6\uff08T\u5f88\u5927\uff09\uff0c\u68af\u5ea6\u4f1a\uff1a"}),(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u68af\u5ea6\u6d88\u5931"}),"\uff1a\u68af\u5ea6\u5728\u53cd\u5411\u4f20\u64ad\u65f6\u6307\u6570\u7ea7\u8870\u51cf\uff0c\u8d8b\u8fd1\u4e8e0"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u68af\u5ea6\u7206\u70b8"}),"\uff1a\u68af\u5ea6\u5728\u53cd\u5411\u4f20\u64ad\u65f6\u6307\u6570\u7ea7\u589e\u957f\uff0c\u8d8b\u8fd1\u4e8e\u65e0\u7a77"]}),"\n"]}),(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u5177\u4f53\u6765\u8bf4\uff1a"})}),(0,r.jsx)(e.p,{children:"\u68af\u5ea6\u8ba1\u7b97\u6d89\u53ca\u591a\u4e2a\u65f6\u95f4\u6b65\u7684\u8fde\u4e58\uff1a"}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u2202L/\u2202h\u2080 = \u2202L/\u2202h\u209c \xd7 \u220f(\u2202h\u209c/\u2202h\u209c\u208b\u2081)\n"})}),(0,r.jsxs)(e.p,{children:["\u5982\u679c\u6bcf\u4e2a\u5bfc\u6570\u9879 < 1\uff0c\u8fde\u4e58\u540e\u4f1a\u8d8b\u8fd1\u4e8e0\uff08\u68af\u5ea6\u6d88\u5931\uff09",(0,r.jsx)(e.br,{}),"\n","\u5982\u679c\u6bcf\u4e2a\u5bfc\u6570\u9879 > 1\uff0c\u8fde\u4e58\u540e\u4f1a\u8d8b\u8fd1\u4e8e\u221e\uff08\u68af\u5ea6\u7206\u70b8\uff09"]}),(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u7ed3\u679c"}),"\uff1a\u6a21\u578b\u65e0\u6cd5\u5b66\u4e60\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\uff08\u4f8b\u5982\uff0c\u53e5\u5b50\u5f00\u5934\u7684\u4e3b\u8bed\u548c\u7ed3\u5c3e\u7684\u8c13\u8bed\u4e4b\u95f4\u7684\u5173\u7cfb\uff09"]})]}),"\n",(0,r.jsx)(e.h2,{id:"lstm-\u7ed3\u6784",children:"LSTM \u7ed3\u6784"}),"\n",(0,r.jsxs)(e.p,{children:["LSTM \u901a\u8fc7\u5f15\u5165",(0,r.jsx)(e.strong,{children:"\u95e8\u63a7\u673a\u5236"}),"\u548c",(0,r.jsx)(e.strong,{children:"\u7ec6\u80de\u72b6\u6001"}),"\u6765\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002"]}),"\n",(0,r.jsx)(e.h3,{id:"\u6838\u5fc3\u7ec4\u4ef6",children:"\u6838\u5fc3\u7ec4\u4ef6"}),"\n",(0,r.jsx)(e.p,{children:"LSTM \u5355\u5143\u5305\u542b\u4e09\u4e2a\u95e8\u548c\u4e00\u4e2a\u7ec6\u80de\u72b6\u6001\uff1a"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u9057\u5fd8\u95e8\uff08Forget Gate\uff09"}),"\uff1a\u51b3\u5b9a\u4ece\u7ec6\u80de\u72b6\u6001\u4e2d\u4e22\u5f03\u4ec0\u4e48\u4fe1\u606f"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u8f93\u5165\u95e8\uff08Input Gate\uff09"}),"\uff1a\u51b3\u5b9a\u4ec0\u4e48\u65b0\u4fe1\u606f\u5b58\u50a8\u5230\u7ec6\u80de\u72b6\u6001"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u8f93\u51fa\u95e8\uff08Output Gate\uff09"}),"\uff1a\u51b3\u5b9a\u8f93\u51fa\u4ec0\u4e48\u4fe1\u606f"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u7ec6\u80de\u72b6\u6001\uff08Cell State\uff09"}),'\uff1a\u4fe1\u606f\u7684"\u9ad8\u901f\u516c\u8def"\uff0c\u68af\u5ea6\u53ef\u4ee5\u7545\u901a\u65e0\u963b\u5730\u6d41\u52a8']}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"\u6570\u5b66\u516c\u5f0f",children:"\u6570\u5b66\u516c\u5f0f"}),"\n",(0,r.jsx)(e.p,{children:"LSTM \u7684\u8ba1\u7b97\u8fc7\u7a0b\uff1a"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# \u8f93\u5165\uff1ax_t\uff08\u5f53\u524d\u8f93\u5165\uff09\u3001h_{t-1}\uff08\u4e0a\u4e00\u65f6\u523b\u9690\u85cf\u72b6\u6001\uff09\u3001c_{t-1}\uff08\u4e0a\u4e00\u65f6\u523b\u7ec6\u80de\u72b6\u6001\uff09\n\n# 1. \u9057\u5fd8\u95e8\uff1a\u51b3\u5b9a\u4e22\u5f03\u591a\u5c11\u65e7\u4fe1\u606f\nf_t = \u03c3(W_f \xb7 [h_{t-1}, x_t] + b_f)\n\n# 2. \u8f93\u5165\u95e8\uff1a\u51b3\u5b9a\u5b58\u50a8\u591a\u5c11\u65b0\u4fe1\u606f\ni_t = \u03c3(W_i \xb7 [h_{t-1}, x_t] + b_i)\nc\u0303_t = tanh(W_c \xb7 [h_{t-1}, x_t] + b_c)  # \u5019\u9009\u7ec6\u80de\u72b6\u6001\n\n# 3. \u66f4\u65b0\u7ec6\u80de\u72b6\u6001\nc_t = f_t \u2299 c_{t-1} + i_t \u2299 c\u0303_t\n\n# 4. \u8f93\u51fa\u95e8\uff1a\u51b3\u5b9a\u8f93\u51fa\u4ec0\u4e48\no_t = \u03c3(W_o \xb7 [h_{t-1}, x_t] + b_o)\nh_t = o_t \u2299 tanh(c_t)\n\n# \u7b26\u53f7\u8bf4\u660e\uff1a\n# \u03c3\uff1asigmoid \u51fd\u6570\uff08\u8f93\u51fa0-1\uff09\n# tanh\uff1a\u53cc\u66f2\u6b63\u5207\u51fd\u6570\uff08\u8f93\u51fa-1\u52301\uff09\n# \u2299\uff1a\u9010\u5143\u7d20\u4e58\u6cd5\n# W\u3001b\uff1a\u53ef\u5b66\u4e60\u7684\u6743\u91cd\u548c\u504f\u7f6e\n"})}),"\n",(0,r.jsxs)(e.admonition,{type:"tip",children:[(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u95e8\u7684\u4f5c\u7528\u7406\u89e3\uff1a"})}),(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u9057\u5fd8\u95e8"})," (f_t)\uff1a\u50cf\u4e00\u4e2a\u8fc7\u6ee4\u5668","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u63a5\u8fd11\uff1a\u4fdd\u7559\u4fe1\u606f"}),"\n",(0,r.jsx)(e.li,{children:"\u63a5\u8fd10\uff1a\u9057\u5fd8\u4fe1\u606f"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u8f93\u5165\u95e8"})," (i_t)\uff1a\u50cf\u4e00\u4e2a\u5f00\u5173","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u63a5\u8fd11\uff1a\u63a5\u53d7\u65b0\u4fe1\u606f"}),"\n",(0,r.jsx)(e.li,{children:"\u63a5\u8fd10\uff1a\u62d2\u7edd\u65b0\u4fe1\u606f"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u8f93\u51fa\u95e8"})," (o_t)\uff1a\u51b3\u5b9a\u8f93\u51fa","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u63a7\u5236\u6709\u591a\u5c11\u7ec6\u80de\u72b6\u6001\u4fe1\u606f\u4f20\u9012\u5230\u4e0b\u4e00\u5c42"}),"\n"]}),"\n"]}),"\n"]}),(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u7c7b\u6bd4\uff1a\u7ec6\u80de\u72b6\u6001\u5c31\u50cf\u4f20\u9001\u5e26"})}),(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u4fe1\u606f\u53ef\u4ee5\u6cbf\u7740\u4f20\u9001\u5e26\u76f4\u63a5\u6d41\u52a8\uff08\u4e0d\u7ecf\u8fc7\u590d\u6742\u7684\u975e\u7ebf\u6027\u53d8\u6362\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u95e8\u673a\u5236\u51b3\u5b9a\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u6dfb\u52a0\u6216\u5220\u9664\u4ec0\u4e48\u4fe1\u606f"}),"\n",(0,r.jsx)(e.li,{children:"\u8fd9\u4f7f\u5f97\u68af\u5ea6\u80fd\u591f\u957f\u8ddd\u79bb\u4f20\u64ad\u800c\u4e0d\u6d88\u5931"}),"\n"]})]}),"\n",(0,r.jsx)(e.h3,{id:"\u7b80\u5316\u7406\u89e3\u7248\u672c",children:"\u7b80\u5316\u7406\u89e3\u7248\u672c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:'import torch\nimport torch.nn as nn\n\n# LSTM \u7684\u7b80\u5316\u7406\u89e3\u7248\u672c\nclass SimplifiedLSTM:\n    """\n    LSTM \u5de5\u4f5c\u6d41\u7a0b\u6f14\u793a\uff08\u975e\u5b9e\u9645\u5b9e\u73b0\uff09\n    """\n    def step(self, x_t, h_prev, c_prev):\n        """\n        x_t: \u5f53\u524d\u8f93\u5165\n        h_prev: \u4e0a\u4e00\u65f6\u523b\u9690\u85cf\u72b6\u6001\n        c_prev: \u4e0a\u4e00\u65f6\u523b\u7ec6\u80de\u72b6\u6001\n        """\n        # \u62fc\u63a5\u8f93\u5165\u548c\u9690\u85cf\u72b6\u6001\n        combined = torch.cat([h_prev, x_t], dim=1)\n        \n        # 1. \u9057\u5fd8\u95e8\uff1a\u8981\u5fd8\u8bb0\u4ec0\u4e48\uff1f\n        f_t = torch.sigmoid(self.W_f @ combined + self.b_f)\n        # \u4f8b\u5982\uff1a\u5728\u9605\u8bfb\u65b0\u53e5\u5b50\u65f6\uff0c\u5fd8\u8bb0\u4e0a\u4e00\u53e5\u7684\u4e3b\u8bed\n        \n        # 2. \u8f93\u5165\u95e8\uff1a\u8981\u8bb0\u4f4f\u4ec0\u4e48\u65b0\u4fe1\u606f\uff1f\n        i_t = torch.sigmoid(self.W_i @ combined + self.b_i)\n        c_tilde = torch.tanh(self.W_c @ combined + self.b_c)\n        # \u4f8b\u5982\uff1a\u8bb0\u4f4f\u65b0\u53e5\u5b50\u7684\u4e3b\u8bed\n        \n        # 3. \u66f4\u65b0\u7ec6\u80de\u72b6\u6001\n        c_t = f_t * c_prev + i_t * c_tilde\n        # \u65e7\u4fe1\u606f \xd7 \u9057\u5fd8\u95e8 + \u65b0\u4fe1\u606f \xd7 \u8f93\u5165\u95e8\n        \n        # 4. \u8f93\u51fa\u95e8\uff1a\u8f93\u51fa\u4ec0\u4e48\uff1f\n        o_t = torch.sigmoid(self.W_o @ combined + self.b_o)\n        h_t = o_t * torch.tanh(c_t)\n        # \u4f8b\u5982\uff1a\u57fa\u4e8e\u4e3b\u8bed\u548c\u4e0a\u4e0b\u6587\u751f\u6210\u5bf9\u5e94\u7684\u8c13\u8bed\n        \n        return h_t, c_t\n\n# \u5b9e\u9645\u4f7f\u7528 PyTorch \u7684 LSTM\nlstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=1, batch_first=True)\n\n# \u8f93\u5165\uff1a(batch_size, seq_len, input_size)\nx = torch.randn(2, 5, 10)  # 2\u4e2a\u6837\u672c\uff0c\u6bcf\u4e2a\u5e8f\u5217\u957f\u5ea65\uff0c\u7279\u5f81\u7ef4\u5ea610\n\n# \u524d\u5411\u4f20\u64ad\noutput, (h_n, c_n) = lstm(x)\n\nprint(f"\u8f93\u51fa\u5f62\u72b6: {output.shape}")      # (2, 5, 20) - \u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\nprint(f"\u6700\u7ec8\u9690\u85cf\u72b6\u6001: {h_n.shape}")     # (1, 2, 20) - \u6700\u540e\u65f6\u523b\u7684h\nprint(f"\u6700\u7ec8\u7ec6\u80de\u72b6\u6001: {c_n.shape}")     # (1, 2, 20) - \u6700\u540e\u65f6\u523b\u7684c\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\u57fa\u7840\u793a\u4f8b",children:"\u57fa\u7840\u793a\u4f8b"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\n\nclass LSTMModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n        super(LSTMModel, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # LSTM \u5c42\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        \n        # \u5168\u8fde\u63a5\u5c42\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        # x: (batch_size, seq_len, input_size)\n        \n        # LSTM \u524d\u5411\u4f20\u64ad\n        # output: (batch_size, seq_len, hidden_size)\n        # (h_n, c_n): \u6700\u540e\u65f6\u523b\u7684\u9690\u85cf\u72b6\u6001\u548c\u7ec6\u80de\u72b6\u6001\n        output, (h_n, c_n) = self.lstm(x)\n        \n        # \u53d6\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\n        last_output = output[:, -1, :]  # (batch_size, hidden_size)\n        \n        # \u901a\u8fc7\u5168\u8fde\u63a5\u5c42\n        out = self.fc(last_output)  # (batch_size, output_size)\n        \n        return out\n\n# \u521b\u5efa\u6a21\u578b\nmodel = LSTMModel(\n    input_size=10,\n    hidden_size=64,\n    num_layers=2,\n    output_size=1,\n    dropout=0.5\n)\n\nprint(model)\n# LSTMModel(\n#   (lstm): LSTM(10, 64, num_layers=2, batch_first=True, dropout=0.5)\n#   (fc): Linear(in_features=64, out_features=1, bias=True)\n# )\n\n# \u6d4b\u8bd5\u524d\u5411\u4f20\u64ad\nx = torch.randn(32, 20, 10)  # 32\u4e2a\u6837\u672c\uff0c\u5e8f\u5217\u957f\u5ea620\uff0c\u7279\u5f81\u7ef4\u5ea610\noutput = model(x)\nprint(f"\u8f93\u51fa\u5f62\u72b6: {output.shape}")  # (32, 1)\n'})}),"\n",(0,r.jsxs)(e.admonition,{type:"tip",children:[(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"PyTorch LSTM \u53c2\u6570\u8bf4\u660e\uff1a"})}),(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"\u53c2\u6570"}),(0,r.jsx)(e.th,{children:"\u8bf4\u660e"}),(0,r.jsx)(e.th,{children:"\u9ed8\u8ba4\u503c"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"input_size"})}),(0,r.jsx)(e.td,{children:"\u8f93\u5165\u7279\u5f81\u7ef4\u5ea6"}),(0,r.jsx)(e.td,{children:"\u5fc5\u9700"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"hidden_size"})}),(0,r.jsx)(e.td,{children:"\u9690\u85cf\u5c42\u7ef4\u5ea6"}),(0,r.jsx)(e.td,{children:"\u5fc5\u9700"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"num_layers"})}),(0,r.jsx)(e.td,{children:"LSTM \u5c42\u6570"}),(0,r.jsx)(e.td,{children:"1"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"bias"})}),(0,r.jsx)(e.td,{children:"\u662f\u5426\u4f7f\u7528\u504f\u7f6e"}),(0,r.jsx)(e.td,{children:"True"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"batch_first"})}),(0,r.jsx)(e.td,{children:"\u8f93\u5165\u5f62\u72b6"}),(0,r.jsx)(e.td,{children:"False"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"dropout"})}),(0,r.jsx)(e.td,{children:"Dropout \u6bd4\u7387"}),(0,r.jsx)(e.td,{children:"0"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"bidirectional"})}),(0,r.jsx)(e.td,{children:"\u662f\u5426\u53cc\u5411"}),(0,r.jsx)(e.td,{children:"False"})]})]})]}),(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"batch_first \u53c2\u6570\uff1a"})}),(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"True"}),"\uff1a\u8f93\u5165\u5f62\u72b6\u4e3a ",(0,r.jsx)(e.code,{children:"(batch, seq, feature)"}),"\uff08\u63a8\u8350\uff09"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"False"}),"\uff1a\u8f93\u5165\u5f62\u72b6\u4e3a ",(0,r.jsx)(e.code,{children:"(seq, batch, feature)"}),"\uff08PyTorch\u9ed8\u8ba4\uff09"]}),"\n"]})]}),"\n",(0,r.jsx)(e.h3,{id:"\u5e8f\u5217\u5230\u5e8f\u5217seq2seq",children:"\u5e8f\u5217\u5230\u5e8f\u5217\uff08Seq2Seq\uff09"}),"\n",(0,r.jsx)(e.p,{children:"\u4f7f\u7528 LSTM \u8fdb\u884c\u5e8f\u5217\u8f6c\u6362\uff0c\u5982\u673a\u5668\u7ffb\u8bd1\u3002"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:'import torch\nimport torch.nn as nn\n\nclass Encoder(nn.Module):\n    """\u7f16\u7801\u5668\uff1a\u5c06\u8f93\u5165\u5e8f\u5217\u7f16\u7801\u4e3a\u4e0a\u4e0b\u6587\u5411\u91cf"""\n    def __init__(self, input_size, embedding_dim, hidden_size, num_layers):\n        super().__init__()\n        self.embedding = nn.Embedding(input_size, embedding_dim)\n        self.lstm = nn.LSTM(\n            embedding_dim,\n            hidden_size,\n            num_layers,\n            batch_first=True\n        )\n    \n    def forward(self, x):\n        # x: (batch_size, seq_len)\n        embedded = self.embedding(x)  # (batch, seq, emb)\n        outputs, (h_n, c_n) = self.lstm(embedded)\n        return h_n, c_n  # \u8fd4\u56de\u6700\u7ec8\u72b6\u6001\u4f5c\u4e3a\u4e0a\u4e0b\u6587\n\nclass Decoder(nn.Module):\n    """\u89e3\u7801\u5668\uff1a\u6839\u636e\u4e0a\u4e0b\u6587\u751f\u6210\u8f93\u51fa\u5e8f\u5217"""\n    def __init__(self, output_size, embedding_dim, hidden_size, num_layers):\n        super().__init__()\n        self.embedding = nn.Embedding(output_size, embedding_dim)\n        self.lstm = nn.LSTM(\n            embedding_dim,\n            hidden_size,\n            num_layers,\n            batch_first=True\n        )\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x, h_0, c_0):\n        # x: (batch_size, seq_len)\n        # h_0, c_0: \u7f16\u7801\u5668\u7684\u6700\u7ec8\u72b6\u6001\n        embedded = self.embedding(x)\n        outputs, (h_n, c_n) = self.lstm(embedded, (h_0, c_0))\n        predictions = self.fc(outputs)  # (batch, seq, vocab)\n        return predictions, (h_n, c_n)\n\nclass Seq2Seq(nn.Module):\n    """\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b"""\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n    \n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        # src: (batch_size, src_len) \u6e90\u8bed\u8a00\n        # trg: (batch_size, trg_len) \u76ee\u6807\u8bed\u8a00\n        \n        batch_size = trg.shape[0]\n        trg_len = trg.shape[1]\n        trg_vocab_size = self.decoder.fc.out_features\n        \n        # \u5b58\u50a8\u89e3\u7801\u5668\u8f93\u51fa\n        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size)\n        \n        # \u7f16\u7801\u5668\n        h, c = self.encoder(src)\n        \n        # \u89e3\u7801\u5668\u7b2c\u4e00\u4e2a\u8f93\u5165\uff08<SOS> token\uff09\n        input = trg[:, 0].unsqueeze(1)\n        \n        # \u9010\u6b65\u89e3\u7801\n        for t in range(1, trg_len):\n            output, (h, c) = self.decoder(input, h, c)\n            outputs[:, t, :] = output.squeeze(1)\n            \n            # Teacher forcing\uff1a\u968f\u673a\u4f7f\u7528\u771f\u5b9e\u503c\u6216\u9884\u6d4b\u503c\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(2)\n            input = trg[:, t].unsqueeze(1) if teacher_force else top1\n        \n        return outputs\n\n# \u521b\u5efa Seq2Seq \u6a21\u578b\nencoder = Encoder(\n    input_size=10000,      # \u6e90\u8bed\u8a00\u8bcd\u6c47\u8868\u5927\u5c0f\n    embedding_dim=256,\n    hidden_size=512,\n    num_layers=2\n)\n\ndecoder = Decoder(\n    output_size=8000,      # \u76ee\u6807\u8bed\u8a00\u8bcd\u6c47\u8868\u5927\u5c0f\n    embedding_dim=256,\n    hidden_size=512,\n    num_layers=2\n)\n\nmodel = Seq2Seq(encoder, decoder)\n\n# \u793a\u4f8b\u8f93\u5165\nsrc = torch.randint(0, 10000, (32, 20))  # \u6e90\u5e8f\u5217\ntrg = torch.randint(0, 8000, (32, 15))   # \u76ee\u6807\u5e8f\u5217\n\n# \u524d\u5411\u4f20\u64ad\noutputs = model(src, trg, teacher_forcing_ratio=0.5)\nprint(f"\u8f93\u51fa\u5f62\u72b6: {outputs.shape}")  # (32, 15, 8000)\n'})}),"\n",(0,r.jsxs)(e.admonition,{type:"tip",children:[(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Seq2Seq \u5173\u952e\u6982\u5ff5\uff1a"})}),(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Teacher Forcing"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u8bad\u7ec3\u65f6\uff1a\u4f7f\u7528\u771f\u5b9e\u76ee\u6807\u5e8f\u5217\u4f5c\u4e3a\u89e3\u7801\u5668\u8f93\u5165\uff08\u52a0\u901f\u6536\u655b\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u63a8\u7406\u65f6\uff1a\u4f7f\u7528\u6a21\u578b\u81ea\u5df1\u7684\u9884\u6d4b\u4f5c\u4e3a\u4e0b\u4e00\u6b65\u8f93\u5165"}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# \u8bad\u7ec3\u65f6\ninput = trg[:, t]  # \u4f7f\u7528\u771f\u5b9e\u503c\n\n# \u63a8\u7406\u65f6\ninput = prediction  # \u4f7f\u7528\u9884\u6d4b\u503c\n"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u7f16\u7801\u5668\uff1a\u538b\u7f29\u6e90\u5e8f\u5217\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684\u4e0a\u4e0b\u6587\u5411\u91cf"}),"\n",(0,r.jsx)(e.li,{children:"\u89e3\u7801\u5668\uff1a\u6839\u636e\u4e0a\u4e0b\u6587\u751f\u6210\u76ee\u6807\u5e8f\u5217"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u6ce8\u610f\u529b\u673a\u5236\uff08\u540e\u7eed\u6539\u8fdb\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u89e3\u51b3\u56fa\u5b9a\u957f\u5ea6\u4e0a\u4e0b\u6587\u7684\u74f6\u9888"}),"\n",(0,r.jsx)(e.li,{children:"\u8ba9\u89e3\u7801\u5668\u5728\u6bcf\u6b65\u5173\u6ce8\u7f16\u7801\u5668\u7684\u4e0d\u540c\u90e8\u5206"}),"\n"]}),"\n"]}),"\n"]})]}),"\n",(0,r.jsx)(e.h3,{id:"\u6587\u672c\u60c5\u611f\u5206\u6790",children:"\u6587\u672c\u60c5\u611f\u5206\u6790"}),"\n",(0,r.jsx)(e.p,{children:"\u60c5\u611f\u5206\u6790\u793a\u4f8b\uff08\u5b8c\u6574\u53ef\u8fd0\u884c\uff09\u3002"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# \u81ea\u5b9a\u4e49\u6570\u636e\u96c6\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels, vocab, max_len=100):\n        self.texts = texts\n        self.labels = labels\n        self.vocab = vocab\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        \n        # \u6587\u672c\u8f6c\u7d22\u5f15\n        indices = [self.vocab.get(word, self.vocab['<UNK>']) for word in text.split()]\n        \n        # \u586b\u5145\u6216\u622a\u65ad\n        if len(indices) < self.max_len:\n            indices += [self.vocab['<PAD>']] * (self.max_len - len(indices))\n        else:\n            indices = indices[:self.max_len]\n        \n        return torch.LongTensor(indices), torch.LongTensor([label])\n\n# \u6a21\u578b\u5b9a\u4e49\nclass SentimentLSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, num_classes):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(\n            embedding_dim,\n            hidden_size,\n            num_layers,\n            batch_first=True,\n            dropout=0.5\n        )\n        self.fc = nn.Linear(hidden_size, num_classes)\n    \n    def forward(self, x):\n        embedded = self.embedding(x)\n        lstm_out, (h_n, c_n) = self.lstm(embedded)\n        \n        # \u53d6\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\uff08\u6216\u4f7f\u7528\u5e73\u5747\u6c60\u5316\uff09\n        last_hidden = lstm_out[:, -1, :]\n        out = self.fc(last_hidden)\n        return out\n\n# \u793a\u4f8b\u6570\u636e\ntexts = [\n    \"I love this movie\",\n    \"This is terrible\",\n    \"Great performance\",\n    \"Waste of time\"\n]\nlabels = [1, 0, 1, 0]  # 1=\u6b63\u9762, 0=\u8d1f\u9762\n\n# \u6784\u5efa\u8bcd\u6c47\u8868\uff08\u7b80\u5316\uff09\nvocab = {\n    '<PAD>': 0,\n    '<UNK>': 1,\n    'I': 2,\n    'love': 3,\n    'this': 4,\n    'movie': 5,\n    'is': 6,\n    'terrible': 7,\n    'Great': 8,\n    'performance': 9,\n    'Waste': 10,\n    'of': 11,\n    'time': 12\n}\n\n# \u521b\u5efa\u6570\u636e\u96c6\u548c\u6570\u636e\u52a0\u8f7d\u5668\ndataset = SentimentDataset(texts, labels, vocab, max_len=20)\ndataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n\n# \u521b\u5efa\u6a21\u578b\nmodel = SentimentLSTM(\n    vocab_size=len(vocab),\n    embedding_dim=50,\n    hidden_size=128,\n    num_layers=2,\n    num_classes=2\n)\n\n# \u8bad\u7ec3\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# \u8bad\u7ec3\u5faa\u73af\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    \n    for batch_texts, batch_labels in dataloader:\n        # \u524d\u5411\u4f20\u64ad\n        outputs = model(batch_texts)\n        loss = criterion(outputs, batch_labels.squeeze())\n        \n        # \u53cd\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    avg_loss = total_loss / len(dataloader)\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n\n# \u9884\u6d4b\nmodel.eval()\ntest_text = \"I love this\"\ntest_indices = [vocab.get(word, vocab['<UNK>']) for word in test_text.split()]\ntest_indices += [vocab['<PAD>']] * (20 - len(test_indices))\ntest_tensor = torch.LongTensor([test_indices])\n\nwith torch.no_grad():\n    output = model(test_tensor)\n    prediction = torch.argmax(output, dim=1)\n    print(f\"\u9884\u6d4b\u7ed3\u679c: {'\u6b63\u9762' if prediction.item() == 1 else '\u8d1f\u9762'}\")\n"})}),"\n",(0,r.jsx)(e.h3,{id:"bidirectional-lstm\u53cc\u5411lstm",children:"Bidirectional LSTM\uff08\u53cc\u5411LSTM\uff09"}),"\n",(0,r.jsx)(e.p,{children:"\u53cc\u5411 LSTM \u540c\u65f6\u4ece\u524d\u5411\u540e\u548c\u4ece\u540e\u5411\u524d\u5904\u7406\u5e8f\u5217\uff0c\u80fd\u591f\u6355\u83b7\u53cc\u5411\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:'import torch\nimport torch.nn as nn\n\nclass BiLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size):\n        super().__init__()\n        \n        # \u53cc\u5411 LSTM\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            bidirectional=True  # \u5173\u952e\u53c2\u6570\n        )\n        \n        # \u6ce8\u610f\uff1a\u53cc\u5411LSTM\u7684\u8f93\u51fa\u7ef4\u5ea6\u662f hidden_size * 2\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n    \n    def forward(self, x):\n        # x: (batch_size, seq_len, input_size)\n        \n        # LSTM\u8f93\u51fa\n        # output: (batch_size, seq_len, hidden_size * 2)\n        # h_n: (num_layers * 2, batch_size, hidden_size)\n        output, (h_n, c_n) = self.lstm(x)\n        \n        # \u53d6\u6700\u540e\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\n        last_output = output[:, -1, :]  # (batch_size, hidden_size * 2)\n        \n        # \u5206\u7c7b\n        out = self.fc(last_output)\n        return out\n\n# \u4f7f\u7528\nmodel = BiLSTM(input_size=10, hidden_size=64, num_layers=2, output_size=2)\nx = torch.randn(32, 20, 10)\noutput = model(x)\nprint(f"\u8f93\u51fa\u5f62\u72b6: {output.shape}")  # (32, 2)\n'})}),"\n",(0,r.jsxs)(e.admonition,{type:"tip",children:[(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u53cc\u5411 LSTM \u7684\u4f18\u52bf\uff1a"})}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# \u5355\u5411 LSTM\uff1a\u53ea\u80fd\u770b\u5230\u8fc7\u53bb\n"\u6211 \u7231 \u5403 [\u82f9\u679c]" \u2192 \u53ea\u770b\u5230 "\u6211 \u7231 \u5403"\n\n# \u53cc\u5411 LSTM\uff1a\u65e2\u770b\u8fc7\u53bb\u53c8\u770b\u672a\u6765\n"\u6211 \u7231 \u5403 [\u82f9\u679c]" \u2192 \u770b\u5230 "\u6211 \u7231 \u5403" + "\uff08\u672a\u6765\u6ca1\u6709\u4e86\uff09"\n"\u6211 \u7231 \u5403 [\u82f9\u679c] \u548c \u9999\u8549" \u2192 \u770b\u5230 "\u6211 \u7231 \u5403" + "\u548c \u9999\u8549"\n\n# \u9002\u7528\u573a\u666f\uff1a\n- \u2705 \u6587\u672c\u5206\u7c7b\uff08\u6574\u4e2a\u53e5\u5b50\u5df2\u77e5\uff09\n- \u2705 \u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08\u9700\u8981\u4e0a\u4e0b\u6587\uff09\n- \u2705 \u8bcd\u6027\u6807\u6ce8\n- \u274c \u5b9e\u65f6\u9884\u6d4b\uff08\u672a\u6765\u4fe1\u606f\u672a\u77e5\uff09\n- \u274c \u6587\u672c\u751f\u6210\uff08\u9010\u5b57\u751f\u6210\uff09\n'})})]}),"\n",(0,r.jsx)(e.h2,{id:"\u8bad\u7ec3\u6280\u5de7",children:"\u8bad\u7ec3\u6280\u5de7"}),"\n",(0,r.jsx)(e.h3,{id:"\u68af\u5ea6\u88c1\u526a",children:"\u68af\u5ea6\u88c1\u526a"}),"\n",(0,r.jsx)(e.p,{children:"\u9632\u6b62\u68af\u5ea6\u7206\u70b8\u7684\u91cd\u8981\u6280\u672f\u3002"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nmodel = LSTMModel(...)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.MSELoss()\n\n# \u8bad\u7ec3\u5faa\u73af\nfor epoch in range(num_epochs):\n    for batch_x, batch_y in dataloader:\n        # \u524d\u5411\u4f20\u64ad\n        outputs = model(batch_x)\n        loss = criterion(outputs, batch_y)\n        \n        # \u53cd\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # \u68af\u5ea6\u88c1\u526a\uff08\u91cd\u8981\uff01\uff09\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n        # \u6216\u4f7f\u7528\u503c\u88c1\u526a\n        # torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=0.5)\n        \n        optimizer.step()\n"})}),"\n",(0,r.jsxs)(e.admonition,{type:"tip",children:[(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u68af\u5ea6\u88c1\u526a\u65b9\u6cd5\uff1a"})}),(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u68af\u5ea6\u8303\u6570\u88c1\u526a\uff08\u63a8\u8350\uff09"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n# \u5982\u679c\u68af\u5ea6\u8303\u6570 > 5.0\uff0c\u7f29\u653e\u68af\u5ea6\n"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u68af\u5ea6\u503c\u88c1\u526a"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=0.5)\n# \u6bcf\u4e2a\u68af\u5ea6\u503c\u9650\u5236\u5728 [-0.5, 0.5]\n"})}),"\n"]}),"\n"]}),(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u4f55\u65f6\u4f7f\u7528\uff1a"})}),(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"LSTM/GRU\uff1a\u51e0\u4e4e\u603b\u662f\u4f7f\u7528"}),"\n",(0,r.jsx)(e.li,{children:"\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff1a\u5c1d\u8bd5\u88c1\u526a"}),"\n",(0,r.jsx)(e.li,{children:"loss \u51fa\u73b0 NaN\uff1a\u964d\u4f4e max_norm"}),"\n"]}),(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u63a8\u8350\u503c\uff1a"})}),(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"max_norm: 1.0 - 10.0\uff08\u5e38\u75285.0\uff09"}),"\n"]})]}),"\n",(0,r.jsx)(e.h3,{id:"\u8fc7\u62df\u5408\u9632\u6b62",children:"\u8fc7\u62df\u5408\u9632\u6b62"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:'import torch\nimport torch.nn as nn\n\nclass RobustLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n        super().__init__()\n        \n        self.embedding = nn.Embedding(input_size, 128)\n        \n        # 1. LSTM dropout\uff08\u5c42\u95f4\uff09\n        self.lstm = nn.LSTM(\n            128,\n            hidden_size,\n            num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        \n        # 2. \u989d\u5916\u7684 dropout\n        self.dropout = nn.Dropout(dropout)\n        \n        # 3. \u5168\u8fde\u63a5\u5c42\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        embedded = self.embedding(x)\n        \n        # LSTM\n        lstm_out, _ = self.lstm(embedded)\n        \n        # Dropout\n        dropped = self.dropout(lstm_out[:, -1, :])\n        \n        # \u8f93\u51fa\n        out = self.fc(dropped)\n        return out\n\n# \u5176\u4ed6\u9632\u6b62\u8fc7\u62df\u5408\u7684\u65b9\u6cd5\n\n# 4. \u6743\u91cd\u8870\u51cf\uff08L2\u6b63\u5219\u5316\uff09\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n\n# 5. \u65e9\u505c\uff08Early Stopping\uff09\nclass EarlyStopping:\n    def __init__(self, patience=7, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n    \n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0\n\n# \u4f7f\u7528\u65e9\u505c\nearly_stopping = EarlyStopping(patience=10)\n\nfor epoch in range(num_epochs):\n    train_loss = train_one_epoch(model, train_loader)\n    val_loss = validate(model, val_loader)\n    \n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(f"Early stopping at epoch {epoch}")\n        break\n\n# 6. \u6570\u636e\u589e\u5f3a\n# \u5bf9\u4e8e\u6587\u672c\uff1a\u540c\u4e49\u8bcd\u66ff\u6362\u3001\u968f\u673a\u5220\u9664\u3001\u56de\u8bd1\n# \u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\uff1a\u6dfb\u52a0\u566a\u58f0\u3001\u65f6\u95f4\u626d\u66f2\n'})}),"\n",(0,r.jsxs)(e.admonition,{type:"tip",children:[(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u9632\u6b62\u8fc7\u62df\u5408\u7684\u65b9\u6cd5\u4f18\u5148\u7ea7\uff1a"})}),(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u589e\u52a0\u6570\u636e"}),"\uff08\u6700\u6709\u6548\uff09"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Dropout"}),"\uff080.3-0.5\uff09"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u6743\u91cd\u8870\u51cf"}),"\uff081e-4 \u5230 1e-6\uff09"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u65e9\u505c"}),"\uff08\u76d1\u63a7\u9a8c\u8bc1\u96c6\uff09"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6"}),"\uff08\u51cf\u5c11\u5c42\u6570\u6216\u9690\u85cf\u5355\u5143\uff09"]}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"\u6570\u636e\u589e\u5f3a"})}),"\n"]}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# \u5b8c\u6574\u914d\u7f6e\u793a\u4f8b\nmodel = nn.LSTM(..., dropout=0.5)  # LSTM dropout\noptimizer = Adam(..., weight_decay=1e-5)  # L2\u6b63\u5219\nscheduler = ReduceLROnPlateau(...)  # \u5b66\u4e60\u7387\u8c03\u5ea6\nearly_stopping = EarlyStopping(patience=10)  # \u65e9\u505c\n"})})]}),"\n",(0,r.jsx)(e.h3,{id:"\u5b66\u4e60\u7387\u8c03\u5ea6",children:"\u5b66\u4e60\u7387\u8c03\u5ea6"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:"import torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n\nmodel = LSTMModel(...)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# \u65b9\u5f0f1\uff1a\u9a8c\u8bc1\u96c6loss\u4e0d\u4e0b\u964d\u65f6\u964d\u4f4e\u5b66\u4e60\u7387\nscheduler = ReduceLROnPlateau(\n    optimizer,\n    mode='min',          # \u76d1\u63a7\u6307\u6807\u662f\u5426\u5e94\u8be5\u964d\u4f4e\n    factor=0.5,          # \u5b66\u4e60\u7387\u7f29\u653e\u56e0\u5b50\n    patience=5,          # \u5bb9\u5fcd\u591a\u5c11\u4e2aepoch\n    verbose=True\n)\n\nfor epoch in range(num_epochs):\n    train_loss = train(model, train_loader)\n    val_loss = validate(model, val_loader)\n    \n    # \u66f4\u65b0\u5b66\u4e60\u7387\n    scheduler.step(val_loss)\n\n# \u65b9\u5f0f2\uff1a\u4f59\u5f26\u9000\u706b\nscheduler = CosineAnnealingLR(\n    optimizer,\n    T_max=50,     # \u5468\u671f\n    eta_min=1e-6  # \u6700\u5c0f\u5b66\u4e60\u7387\n)\n\nfor epoch in range(num_epochs):\n    train(model, train_loader)\n    scheduler.step()  # \u6bcf\u4e2aepoch\u540e\u66f4\u65b0\n\n# \u65b9\u5f0f3\uff1a\u5206\u6bb5\u5e38\u6570\nscheduler = optim.lr_scheduler.StepLR(\n    optimizer,\n    step_size=30,  # \u6bcf30\u4e2aepoch\n    gamma=0.1      # \u5b66\u4e60\u7387\u4e58\u4ee50.1\n)\n"})}),"\n",(0,r.jsx)(e.h3,{id:"\u8c03\u8bd5\u6280\u5de7",children:"\u8c03\u8bd5\u6280\u5de7"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:'import torch\nimport torch.nn as nn\n\n# 1. \u68c0\u67e5\u8f93\u5165\u8f93\u51fa\u5f62\u72b6\ndef check_shapes(model, input_shape):\n    x = torch.randn(*input_shape)\n    print(f"\u8f93\u5165\u5f62\u72b6: {x.shape}")\n    \n    output = model(x)\n    print(f"\u8f93\u51fa\u5f62\u72b6: {output.shape}")\n    \n    # \u68c0\u67e5\u4e2d\u95f4\u5c42\n    for name, module in model.named_modules():\n        if isinstance(module, nn.LSTM):\n            print(f"{name} - LSTM\u5c42")\n\n# 2. \u68c0\u67e5\u68af\u5ea6\ndef check_gradients(model):\n    for name, param in model.named_parameters():\n        if param.grad is not None:\n            grad_norm = param.grad.norm().item()\n            print(f"{name}: \u68af\u5ea6\u8303\u6570 = {grad_norm:.4f}")\n            \n            if grad_norm == 0:\n                print(f"  \u8b66\u544a\uff1a{name} \u7684\u68af\u5ea6\u4e3a0\uff01")\n            elif grad_norm > 100:\n                print(f"  \u8b66\u544a\uff1a{name} \u7684\u68af\u5ea6\u8fc7\u5927\uff01")\n\n# 3. \u68c0\u67e5\u6743\u91cd\ndef check_weights(model):\n    for name, param in model.named_parameters():\n        print(f"{name}:")\n        print(f"  \u5747\u503c: {param.data.mean():.4f}")\n        print(f"  \u6807\u51c6\u5dee: {param.data.std():.4f}")\n        print(f"  \u6700\u5c0f\u503c: {param.data.min():.4f}")\n        print(f"  \u6700\u5927\u503c: {param.data.max():.4f}")\n\n# \u4f7f\u7528\nmodel = LSTMModel(...)\ncheck_shapes(model, (32, 50, 10))\n\n# \u8bad\u7ec3\u4e00\u6b65\u540e\u68c0\u67e5\u68af\u5ea6\nloss.backward()\ncheck_gradients(model)\ncheck_weights(model)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\u6027\u80fd\u4f18\u5316",children:"\u6027\u80fd\u4f18\u5316"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",metastring:"showLineNumbers",children:"import torch\nimport torch.nn as nn\n\n# 1. \u4f7f\u7528 GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\nx = x.to(device)\n\n# 2. \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff08\u51cf\u5c11\u5185\u5b58\uff0c\u52a0\u901f\u8bad\u7ec3\uff09\nfrom torch.cuda.amp import autocast, GradScaler\n\nscaler = GradScaler()\n\nfor epoch in range(num_epochs):\n    for batch_x, batch_y in dataloader:\n        batch_x = batch_x.to(device)\n        batch_y = batch_y.to(device)\n        \n        optimizer.zero_grad()\n        \n        # \u4f7f\u7528\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\n        with autocast():\n            outputs = model(batch_x)\n            loss = criterion(outputs, batch_y)\n        \n        # \u7f29\u653e\u68af\u5ea6\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n# 3. DataLoader \u4f18\u5316\ndataloader = DataLoader(\n    dataset,\n    batch_size=64,\n    shuffle=True,\n    num_workers=4,      # \u591a\u8fdb\u7a0b\u52a0\u8f7d\u6570\u636e\n    pin_memory=True     # \u52a0\u901f\u6570\u636e\u4f20\u8f93\u5230GPU\n)\n\n# 4. \u6a21\u578b\u7f16\u8bd1\uff08PyTorch 2.0+\uff09\nmodel = torch.compile(model)  # \u81ea\u52a8\u4f18\u5316\n"})}),"\n",(0,r.jsxs)(e.admonition,{type:"tip",children:[(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u6027\u80fd\u4f18\u5316\u5efa\u8bae\uff1a"})}),(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u6279\u6b21\u5927\u5c0f"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"GPU\uff1a\u5c3d\u91cf\u5927\uff08\u53d7\u663e\u5b58\u9650\u5236\uff09"}),"\n",(0,r.jsx)(e.li,{children:"CPU\uff1a32-128"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u5e8f\u5217\u957f\u5ea6"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u5c3d\u91cf\u4e0d\u8981\u592a\u957f\uff08\u8ba1\u7b97\u590d\u6742\u5ea6 O(n\xb2)\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u53ef\u4ee5\u622a\u65ad\u6216\u91c7\u6837"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u9690\u85cf\u5c42\u5927\u5c0f"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u5e38\u7528\uff1a64\u3001128\u3001256\u3001512"}),"\n",(0,r.jsx)(e.li,{children:"\u592a\u5c0f\uff1a\u6b20\u62df\u5408"}),"\n",(0,r.jsx)(e.li,{children:"\u592a\u5927\uff1a\u8fc7\u62df\u5408\u3001\u6162"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u5c42\u6570"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"1-2\u5c42\uff1a\u5927\u591a\u6570\u4efb\u52a1\u591f\u7528"}),"\n",(0,r.jsx)(e.li,{children:"3-4\u5c42\uff1a\u590d\u6742\u4efb\u52a1"}),"\n"]}),"\n"]}),"\n"]}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# \u6027\u80fd\u5bf9\u6bd4\u6d4b\u8bd5\nimport time\n\nconfigs = [\n    {'hidden': 64, 'layers': 1},\n    {'hidden': 128, 'layers': 2},\n    {'hidden': 256, 'layers': 3}\n]\n\nfor config in configs:\n    model = LSTMModel(hidden_size=config['hidden'], \n                      num_layers=config['layers'])\n    start = time.time()\n    train(model)\n    duration = time.time() - start\n    print(f\"\u914d\u7f6e {config}: {duration:.2f}\u79d2\")\n"})})]})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(a,{...n})}):a(n)}},28453:(n,e,s)=>{s.d(e,{R:()=>l,x:()=>d});var i=s(96540);const r={},t=i.createContext(r);function l(n){const e=i.useContext(t);return i.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function d(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:l(n.components),i.createElement(t.Provider,{value:e},n.children)}}}]);